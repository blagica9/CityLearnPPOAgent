{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Унапредување на контрола на енергија со засилено учење: Споредба помеѓу PPO+LSTM и PPO+GNN+LSTM агенти во CityLearn**\n"
      ],
      "metadata": {
        "id": "Fb3ey8IA6LDC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Овој проект има за цел да процени дали интеграцијата на Graph Neural Networks (GNN) во архитектурата на PPO агенти води кон подобро учење и енергетска ефикасност во CityLearn симулирана околина. Тестирани се две архитектури:\n",
        "\n",
        "\n",
        "\n",
        "*   PPO + GNN + LSTM (агент кој користи граф структура за контекстуална размена на информации меѓу згради).\n",
        "*   PPO + LSTM (агент без граф)\n",
        "  \n",
        "\n",
        "\n",
        "Секој агент е трениран под исти услови, со иста reward функција и параметри, за да се добие фер споредба. Целта е да се открие дали додавањето граф води до поефикасни одлуки за управување со батеријата и подобра адаптација кон динамичните барања на енергија.\n"
      ],
      "metadata": {
        "id": "EA18BHMF6a48"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Инсталација на зависности\n"
      ],
      "metadata": {
        "id": "ZB43reBi6hh2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "csrUTkUGWvk4",
        "outputId": "5ed29119-0cfa-44c8-c754-a62b324c138f",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting citylearn==2.3.0\n",
            "  Downloading CityLearn-2.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting doe-xstock>=1.1.0 (from citylearn==2.3.0)\n",
            "  Downloading doe_xstock-1.1.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (from citylearn==2.3.0) (1.2.0)\n",
            "Collecting nrel-pysam (from citylearn==2.3.0)\n",
            "  Downloading nrel_pysam-7.0.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (8.9 kB)\n",
            "Collecting numpy<2.0.0 (from citylearn==2.3.0)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from citylearn==2.3.0) (2.2.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from citylearn==2.3.0) (6.0.2)\n",
            "Collecting scikit-learn<=1.2.2 (from citylearn==2.3.0)\n",
            "  Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.11/dist-packages (from citylearn==2.3.0) (3.20.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from citylearn==2.3.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from citylearn==2.3.0) (0.21.0+cu124)\n",
            "Collecting openstudio<=3.3.0 (from citylearn==2.3.0)\n",
            "  Downloading openstudio-3.3.0-py3-none-manylinux1_x86_64.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from doe-xstock>=1.1.0->citylearn==2.3.0) (4.13.4)\n",
            "Collecting eppy (from doe-xstock>=1.1.0->citylearn==2.3.0)\n",
            "  Downloading eppy-0.5.63-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from doe-xstock>=1.1.0->citylearn==2.3.0) (4.3.8)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from doe-xstock>=1.1.0->citylearn==2.3.0) (18.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from doe-xstock>=1.1.0->citylearn==2.3.0) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<=1.2.2->citylearn==2.3.0) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<=1.2.2->citylearn==2.3.0) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<=1.2.2->citylearn==2.3.0) (3.6.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium->citylearn==2.3.0) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium->citylearn==2.3.0) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium->citylearn==2.3.0) (0.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->citylearn==2.3.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->citylearn==2.3.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->citylearn==2.3.0) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->citylearn==2.3.0) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->citylearn==2.3.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->citylearn==2.3.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->citylearn==2.3.0) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->citylearn==2.3.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->citylearn==2.3.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->citylearn==2.3.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->citylearn==2.3.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->citylearn==2.3.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->citylearn==2.3.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->citylearn==2.3.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->citylearn==2.3.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->citylearn==2.3.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->citylearn==2.3.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->citylearn==2.3.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->citylearn==2.3.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->citylearn==2.3.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->citylearn==2.3.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->citylearn==2.3.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->citylearn==2.3.0) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->citylearn==2.3.0) (11.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->citylearn==2.3.0) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->doe-xstock>=1.1.0->citylearn==2.3.0) (2.7)\n",
            "Collecting munch>=2.0.2 (from eppy->doe-xstock>=1.1.0->citylearn==2.3.0)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting beautifulsoup4 (from doe-xstock>=1.1.0->citylearn==2.3.0)\n",
            "  Downloading beautifulsoup4-4.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting tinynumpy>=1.2.1 (from eppy->doe-xstock>=1.1.0->citylearn==2.3.0)\n",
            "  Downloading tinynumpy-1.2.1.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.11/dist-packages (from eppy->doe-xstock>=1.1.0->citylearn==2.3.0) (4.4.2)\n",
            "Requirement already satisfied: lxml>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from eppy->doe-xstock>=1.1.0->citylearn==2.3.0) (5.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from eppy->doe-xstock>=1.1.0->citylearn==2.3.0) (1.0.0)\n",
            "Collecting pydot3k (from eppy->doe-xstock>=1.1.0->citylearn==2.3.0)\n",
            "  Downloading pydot3k-1.0.17.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyparsing>=2.4.7 in /usr/local/lib/python3.11/dist-packages (from eppy->doe-xstock>=1.1.0->citylearn==2.3.0) (3.2.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->citylearn==2.3.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->doe-xstock>=1.1.0->citylearn==2.3.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->doe-xstock>=1.1.0->citylearn==2.3.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->doe-xstock>=1.1.0->citylearn==2.3.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->doe-xstock>=1.1.0->citylearn==2.3.0) (2025.7.14)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pydot3k->eppy->doe-xstock>=1.1.0->citylearn==2.3.0) (75.2.0)\n",
            "Downloading CityLearn-2.3.0-py3-none-any.whl (379 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.5/379.5 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading doe_xstock-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openstudio-3.3.0-py3-none-manylinux1_x86_64.whl (61.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m126.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nrel_pysam-7.0.0-cp311-cp311-manylinux2014_x86_64.whl (47.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m102.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eppy-0.5.63-py2.py3-none-any.whl (869 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.7/869.7 kB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading beautifulsoup4-4.8.0-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.5/97.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Building wheels for collected packages: tinynumpy, pydot3k\n",
            "  Building wheel for tinynumpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinynumpy: filename=tinynumpy-1.2.1-py3-none-any.whl size=18463 sha256=c14a7c16685f4e05864e4ed34c9ffec0cc903ed6d5250e5afe3a9b7aeb53ef2c\n",
            "  Stored in directory: /root/.cache/pip/wheels/d8/c3/c5/85bd9b13ea6e3c76b0bc39db2b28b7d743a771547bf0fb0bdd\n",
            "  Building wheel for pydot3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pydot3k: filename=pydot3k-1.0.17-py3-none-any.whl size=19038 sha256=323e4094ceba6357daa3f12c0d3414427f7bb1041c1df9db4f29fb01fc910b7b\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/df/1f/e1f65a805151fead9e6d9fcbd1441bcf3bba677c4bb6b61059\n",
            "Successfully built tinynumpy pydot3k\n",
            "Installing collected packages: tinynumpy, nrel-pysam, pydot3k, openstudio, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, munch, beautifulsoup4, nvidia-cusparse-cu12, nvidia-cudnn-cu12, eppy, scikit-learn, nvidia-cusolver-cu12, doe-xstock, citylearn\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.13.4\n",
            "    Uninstalling beautifulsoup4-4.13.4:\n",
            "      Successfully uninstalled beautifulsoup4-4.13.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "yfinance 0.2.65 requires beautifulsoup4>=4.11.1, but you have beautifulsoup4 4.8.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "cuml-cu12 25.6.0 requires scikit-learn>=1.5, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "libpysal 4.13.0 requires beautifulsoup4>=4.10, but you have beautifulsoup4 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed beautifulsoup4-4.8.0 citylearn-2.3.0 doe-xstock-1.1.0 eppy-0.5.63 munch-4.0.0 nrel-pysam-7.0.0 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openstudio-3.3.0 pydot3k-1.0.17 scikit-learn-1.2.2 tinynumpy-1.2.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "6a0c0dcf46a045ee99120ee21a99aeef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: gym 0.25.2\n",
            "Uninstalling gym-0.25.2:\n",
            "  Successfully uninstalled gym-0.25.2\n",
            "Collecting gymnasium==0.29.1\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1) (0.0.4)\n",
            "Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gymnasium\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.2.0\n",
            "    Uninstalling gymnasium-1.2.0:\n",
            "      Successfully uninstalled gymnasium-1.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires gym<=0.25.2, which is not installed.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gymnasium-0.29.1\n",
            "Collecting stable-baselines3==2.2.1 (from stable-baselines3[extra]==2.2.1)\n",
            "  Downloading stable_baselines3-2.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]==2.2.1) (4.12.0.88)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]==2.2.1) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]==2.2.1) (2.18.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]==2.2.1) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]==2.2.1) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]==2.2.1) (13.9.4)\n",
            "Collecting shimmy~=1.3.0 (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]==2.2.1)\n",
            "  Downloading Shimmy-1.3.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]==2.2.1) (11.3.0)\n",
            "Collecting autorom~=0.6.1 (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]==2.2.1)\n",
            "  Downloading AutoROM-0.6.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]==2.2.1) (8.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]==2.2.1) (2.32.3)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]==2.2.1)\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (0.0.4)\n",
            "Collecting ale-py~=0.8.1 (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]==2.2.1)\n",
            "  Downloading ale_py-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]==2.2.1) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]==2.2.1) (1.74.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]==2.2.1) (3.8.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]==2.2.1) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]==2.2.1) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]==2.2.1) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]==2.2.1) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]==2.2.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]==2.2.1) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (2.9.0.post0)\n",
            "Collecting numpy>=1.20 (from stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1)\n",
            "  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]==2.2.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]==2.2.1) (2.19.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]==2.2.1) (6.5.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]==2.2.1) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]==2.2.1) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]==2.2.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]==2.2.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]==2.2.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]==2.2.1) (2025.7.14)\n",
            "Downloading stable_baselines3-2.2.1-py3-none-any.whl (181 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.7/181.7 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading Shimmy-1.3.0-py3-none-any.whl (37 kB)\n",
            "Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m120.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ale_py-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=autorom_accept_rom_license-0.6.1-py3-none-any.whl size=446709 sha256=0da9706eb7d6bdda34ca0f436c44d0a4ae13a089214fcc911b57efee4bbbc4b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/fc/c6/8aa657c0d2089982f2dabd110efc68c61eb49831fdb7397351\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: numpy, AutoROM.accept-rom-license, autorom, ale-py, shimmy, stable-baselines3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: ale-py\n",
            "    Found existing installation: ale-py 0.11.2\n",
            "    Uninstalling ale-py-0.11.2:\n",
            "      Successfully uninstalled ale-py-0.11.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires gym<=0.25.2, which is not installed.\n",
            "citylearn 2.3.0 requires numpy<2.0.0, but you have numpy 2.2.6 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires ale-py>=0.10.1, but you have ale-py 0.8.1 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "yfinance 0.2.65 requires beautifulsoup4>=4.11.1, but you have beautifulsoup4 4.8.0 which is incompatible.\n",
            "cuml-cu12 25.6.0 requires scikit-learn>=1.5, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "libpysal 4.13.0 requires beautifulsoup4>=4.10, but you have beautifulsoup4 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.8.1 autorom-0.6.1 numpy-2.2.6 shimmy-1.3.0 stable-baselines3-2.2.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "4ca7cd5a4df6443f93cf1e47080b6fad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.2.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_scatter-2.1.2%2Bpt20cu118-cp311-cp311-linux_x86_64.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt20cu118\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_sparse-0.6.18%2Bpt20cu118-cp311-cp311-linux_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.16.0)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (2.2.6)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt20cu118\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.12.14)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.2.6)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.7.14)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.14.1)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n",
            "Collecting numpy==1.24.4\n",
            "  Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting scipy==1.10.1\n",
            "  Downloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m112.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.1/34.1 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.6\n",
            "    Uninstalling numpy-2.2.6:\n",
            "      Successfully uninstalled numpy-2.2.6\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.0\n",
            "    Uninstalling scipy-1.16.0:\n",
            "      Successfully uninstalled scipy-1.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires gym<=0.25.2, which is not installed.\n",
            "scikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.10.1 which is incompatible.\n",
            "cvxpy 1.6.7 requires scipy>=1.11.0, but you have scipy 1.10.1 which is incompatible.\n",
            "blosc2 3.6.1 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.10.1 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires scipy>=1.11, but you have scipy 1.10.1 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires ale-py>=0.10.1, but you have ale-py 0.8.1 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "jaxlib 0.5.1 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\n",
            "pymc 5.25.1 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.4 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "yfinance 0.2.65 requires beautifulsoup4>=4.11.1, but you have beautifulsoup4 4.8.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.4 which is incompatible.\n",
            "arviz 0.22.0 requires numpy>=1.26.0, but you have numpy 1.24.4 which is incompatible.\n",
            "arviz 0.22.0 requires scipy>=1.11.0, but you have scipy 1.10.1 which is incompatible.\n",
            "cuml-cu12 25.6.0 requires scikit-learn>=1.5, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.4 which is incompatible.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.4 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "jax 0.5.2 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\n",
            "libpysal 4.13.0 requires beautifulsoup4>=4.10, but you have beautifulsoup4 4.8.0 which is incompatible.\n",
            "xarray 2025.7.1 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.4 scipy-1.10.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "77498e69be624a8984e9b667b4d44171"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboard==2.12.3\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.12.3) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.12.3) (1.74.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.12.3) (2.38.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard==2.12.3)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.12.3) (3.8.2)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.12.3) (1.24.4)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.12.3) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.12.3) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.12.3) (75.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.12.3) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.12.3) (3.1.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.12.3) (0.45.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.12.3) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.12.3) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.12.3) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard==2.12.3) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard==2.12.3) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard==2.12.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard==2.12.3) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard==2.12.3) (2025.7.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard==2.12.3) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.12.3) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard==2.12.3) (3.3.1)\n",
            "Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: google-auth-oauthlib, tensorboard\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.2\n",
            "    Uninstalling google-auth-oauthlib-1.2.2:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-oauthlib-1.0.0 tensorboard-2.12.3\n",
            "Collecting tensorflow==2.12.0\n",
            "  Downloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (25.2.10)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12.0)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.74.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.14.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.5.2)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (18.1.1)\n",
            "Collecting numpy<1.24,>=1.22 (from tensorflow==2.12.0)\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (25.0)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.12.0)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.17.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.3)\n",
            "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.14.1)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.12.0)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.45.1)\n",
            "Requirement already satisfied: jaxlib<=0.5.2,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.5.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.1)\n",
            "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib<=0.7.0,>=0.7.0 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.7.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting ml_dtypes>=0.5.0 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading ml_dtypes-0.5.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.6.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib<=0.6.2,>=0.6.2 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.6.2-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.6.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib<=0.6.1,>=0.6.1 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.6.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.6.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.6.0,>=0.6.0 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.6.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.5.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.5.3,>=0.5.3 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.5.3-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.5.1-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.5.0,>=0.5.0 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.5.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (978 bytes)\n",
            "INFO: pip is still looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.38-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.38,>=0.4.38 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.38-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.37-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.37,>=0.4.36 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.36-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.36-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.4.35-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.35,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.35-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.34-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.34,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.34-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.33-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.33,>=0.4.33 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.33-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.31-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.31,>=0.4.30 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.31-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.30-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.30,>=0.4.27 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.30-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2025.7.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.3.1)\n",
            "Downloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (586.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.0/586.0 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading jax-0.4.30-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m114.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.4.30-cp311-cp311-manylinux2014_x86_64.whl (79.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, protobuf, numpy, keras, gast, jaxlib, jax, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.4\n",
            "    Uninstalling numpy-1.24.4:\n",
            "      Successfully uninstalled numpy-1.24.4\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.5.1\n",
            "    Uninstalling jaxlib-0.5.1:\n",
            "      Successfully uninstalled jaxlib-0.5.1\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.5.2\n",
            "    Uninstalling jax-0.5.2:\n",
            "      Successfully uninstalled jax-0.5.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires gym<=0.25.2, which is not installed.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.10.1 which is incompatible.\n",
            "cvxpy 1.6.7 requires scipy>=1.11.0, but you have scipy 1.10.1 which is incompatible.\n",
            "blosc2 3.6.1 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.0 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.10.1 which is incompatible.\n",
            "flax 0.10.6 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires scipy>=1.11, but you have scipy 1.10.1 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires ale-py>=0.10.1, but you have ale-py 0.8.1 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "pymc 5.25.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "geopandas 1.1.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "yfinance 0.2.65 requires beautifulsoup4>=4.11.1, but you have beautifulsoup4 4.8.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "arviz 0.22.0 requires numpy>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "arviz 0.22.0 requires scipy>=1.11.0, but you have scipy 1.10.1 which is incompatible.\n",
            "cuml-cu12 25.6.0 requires scikit-learn>=1.5, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "bigframes 2.12.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "orbax-checkpoint 0.11.19 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "db-dtypes 1.4.3 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.90 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "libpysal 4.13.0 requires beautifulsoup4>=4.10, but you have beautifulsoup4 4.8.0 which is incompatible.\n",
            "xarray 2025.7.1 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 jax-0.4.30 jaxlib-0.4.30 keras-2.12.0 numpy-1.23.5 protobuf-4.25.8 tensorflow-2.12.0 tensorflow-estimator-2.12.0 wrapt-1.14.1\n"
          ]
        }
      ],
      "source": [
        "!pip install citylearn==2.3.0\n",
        "!pip uninstall -y gym\n",
        "!pip install gymnasium==0.29.1\n",
        "!pip install stable-baselines3[extra]==2.2.1\n",
        "\n",
        "# Torch + CUDA 11.8\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# PyTorch Geometric\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
        "!pip install torch-geometric\n",
        "\n",
        "# Fix NumPy / SciPy / TensorBoard / TensorFlow\n",
        "!pip install numpy==1.24.4 scipy==1.10.1\n",
        "!pip install tensorboard==2.12.3\n",
        "!pip install tensorflow==2.12.0\n",
        "\n",
        "# Restart runtime\n",
        "import os\n",
        "os.kill(os.getpid(), 9)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Средина: CityLearn\n",
        "CityLearn е симулациска околина за паметни згради. Секој агент одлучува колку енергија да складира или искористи од батеријата со цел да се минимизира потрошувачката и да се балансира мрежата.\n"
      ],
      "metadata": {
        "id": "6ZZ1Shd665op"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from citylearn.reward_function import RewardFunction\n",
        "\n",
        "class CustomReward(RewardFunction):\n",
        "    def __init__(self, env_metadata):\n",
        "        super().__init__(env_metadata)\n",
        "\n",
        "    def calculate(self, observations):\n",
        "        rewards_per_building = []\n",
        "        for o in observations:\n",
        "            net_electricity_consumption = o.get('net_electricity_consumption', 0.0)\n",
        "            solar_generation = o.get('solar_generation', 0.0)\n",
        "            battery_soc = o.get('electrical_storage_soc', 0.5)\n",
        "            electricity_price = o.get('electricity_pricing', 0.0)\n",
        "\n",
        "            # =======================================================\n",
        "            # 1. Минимизирање на нето-потрошувачка (пресметана со цена)\n",
        "            # =======================================================\n",
        "            # Награда е негативна вредност на потрошената енергија.\n",
        "            # Ова го поттикнува да купува помалку струја, особено кога е скапа.\n",
        "            # Многу позитивно ако продаваш струја на мрежата (net_electricity_consumption < 0)\n",
        "            reward = -1.0 * net_electricity_consumption * electricity_price\n",
        "\n",
        "            # =======================================================\n",
        "            # 2. Искористување на соларна енергија\n",
        "            # =======================================================\n",
        "            # Позитивна награда за генерирање соларна енергија.\n",
        "            # Можеби не директно *solar_generation*, туку колку таа помогнала\n",
        "            # да се намали купувањето или да се полни батеријата.\n",
        "            # Засега, едноставна позитивна вредност.\n",
        "            reward += 0.2 * solar_generation\n",
        "\n",
        "            # =======================================================\n",
        "            # 3. Управување со батеријата (со оглед на цената)\n",
        "            # =======================================================\n",
        "            # а) Казна за празна батерија кога потрошувачката е висока\n",
        "            if net_electricity_consumption > 0 and battery_soc < 0.1:\n",
        "                reward -= 0.5\n",
        "\n",
        "            # б) Казна за преполна батерија кога има соларна генерација И ниска потрошувачка\n",
        "            # Ова го охрабрува да ја празни за да направи место за соларна.\n",
        "            if battery_soc > 0.9 and net_electricity_consumption < 0.1 and solar_generation > 0.1:\n",
        "                reward -= 0.3\n",
        "\n",
        "            #  в) Награда за полнење кога цената е ниска (купувај евтино)\n",
        "            # Ова претпоставува дека ниска цена е < 0.1 (пример).\n",
        "            # Прилагоди го прагот според реалните цени во твојата симулација.\n",
        "            # Ако агентот одлучил да купи струја (акција > 0, т.е. полни батерија)\n",
        "            # и цената е ниска.\n",
        "            if electricity_price < 0.1 and o.get('charging_rate', 0.0) > 0: # Додавање на 'charging_rate' ако е достапно\n",
        "                reward += 0.1 # Мал поттик за евтино полнење\n",
        "\n",
        "            #  г) Награда за празнење кога цената е висока (продавај или користи скапо складирана енергија)\n",
        "            # Ако агентот одлучил да празни (акција < 0, т.е. празни батерија)\n",
        "            # и цената е висока.\n",
        "            if electricity_price > 0.5 and o.get('discharging_rate', 0.0) > 0:\n",
        "                reward += 0.1\n",
        "\n",
        "            # д) Мала казна за отстапување од средина (сеуште корисно)\n",
        "            reward -= 0.05 * abs(battery_soc - 0.5)\n",
        "\n",
        "            rewards_per_building.append(np.clip(reward, -20.0, 20.0))\n",
        "\n",
        "        return rewards_per_building"
      ],
      "metadata": {
        "id": "8uRfLh2DkAnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Архитектура 1: PPO + LSTM + GNN**"
      ],
      "metadata": {
        "id": "atkS6Qp4ociP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch_geometric.nn import GATv2Conv\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from gymnasium import Env, spaces\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
        "from stable_baselines3.common.policies import ActorCriticPolicy\n",
        "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback\n",
        "from citylearn.citylearn import CityLearnEnv\n",
        "from citylearn.reward_function import RewardFunction\n",
        "\n",
        "# ========== Custom Reward ==========\n",
        "# class CustomReward(RewardFunction):\n",
        "#     def __init__(self, env_metadata):\n",
        "#         super().__init__(env_metadata)\n",
        "\n",
        "#     def calculate(self, observations):\n",
        "#         rewards_per_building = []\n",
        "#         for o in observations:\n",
        "#             net_electricity_consumption = o.get('net_electricity_consumption', 0.0)\n",
        "#             solar_generation = o.get('solar_generation', 0.0)\n",
        "#             battery_soc = o.get('electrical_storage_soc', 0.5)\n",
        "\n",
        "#             reward = -1.0 * net_electricity_consumption\n",
        "#             reward += 0.2 * solar_generation\n",
        "\n",
        "#             if net_electricity_consumption > 0 and battery_soc < 0.1:\n",
        "#                 reward -= 0.5\n",
        "\n",
        "#             if battery_soc > 0.9 and net_electricity_consumption < 0.1 and solar_generation > 0.1:\n",
        "#                 reward -= 0.3\n",
        "\n",
        "#             if net_electricity_consumption > 0.5 and battery_soc > 0.2:\n",
        "#                 reward += 0.1 * (battery_soc - 0.2)\n",
        "\n",
        "#             reward -= 0.05 * abs(battery_soc - 0.5)\n",
        "\n",
        "#             rewards_per_building.append(np.clip(reward, -20.0, 20.0))\n",
        "#         return rewards_per_building\n",
        "\n",
        "# ========== Dynamic Graph Builder ==========\n",
        "def build_dynamic_graph(env, k=2):\n",
        "    n = len(env.buildings)\n",
        "    feats = []\n",
        "    for b in env.buildings:\n",
        "        feats.append([\n",
        "            b.net_electricity_consumption[-1],\n",
        "            b.solar_generation[-1],\n",
        "            b.electrical_storage.soc[-1]\n",
        "        ])\n",
        "    features = np.array(feats)\n",
        "    features = StandardScaler().fit_transform(features)\n",
        "    dists = euclidean_distances(features)\n",
        "\n",
        "    edge_index, edge_attr = [], []\n",
        "    for i in range(n):\n",
        "        nearest = np.argsort(dists[i])[1:k+1]\n",
        "        for j in nearest:\n",
        "            weight = 1.0 / (dists[i][j] + 1e-6)\n",
        "            edge_index += [[i, j], [j, i]]\n",
        "            edge_attr += [[weight], [weight]]\n",
        "\n",
        "    return (\n",
        "        torch.tensor(features, dtype=torch.float32),\n",
        "        torch.tensor(edge_index).T.long(),\n",
        "        torch.tensor(edge_attr).float()\n",
        "    )\n",
        "\n",
        "# ========== Env Wrapper ==========\n",
        "class CityLearnSingleBuildingWrapper(Env):\n",
        "    def __init__(self, env, building_id=0, seq_len=12):\n",
        "        super().__init__()\n",
        "        self.env = env\n",
        "        self.building_id = building_id\n",
        "        self.seq_len = seq_len\n",
        "        self.n_buildings = len(env.action_space)\n",
        "        self.obs_dim = env.observation_space[building_id].shape[0]\n",
        "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(seq_len * self.obs_dim,), dtype=np.float32)\n",
        "        self.buffer = []\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        obs, _ = self.env.reset(**kwargs)\n",
        "        self.buffer = []\n",
        "        o = obs[self.building_id]\n",
        "        for _ in range(self.seq_len):\n",
        "            self.buffer.append(o)\n",
        "        return np.concatenate(self.buffer), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        actions = [[0.0] * self.env.action_space[0].shape[0] for _ in range(self.n_buildings)]\n",
        "        actions[self.building_id] = [float(action[0])]\n",
        "        obs, reward, done, trunc, info = self.env.step(actions)\n",
        "        o = obs[self.building_id]\n",
        "        self.buffer.pop(0)\n",
        "        self.buffer.append(o)\n",
        "        return np.concatenate(self.buffer), reward[self.building_id], done, trunc, info\n",
        "\n",
        "# ========== Feature Extractor ==========\n",
        "class GNN_LSTM_FeatureExtractor(BaseFeaturesExtractor):\n",
        "    def __init__(self, observation_space, env, hidden_size=64, lstm_layers=1):\n",
        "        super().__init__(observation_space, features_dim=hidden_size)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.obs_dim = observation_space.shape[0] // 12\n",
        "        self.lstm = nn.LSTM(self.obs_dim, hidden_size, lstm_layers, batch_first=True)\n",
        "        self.hidden = None\n",
        "        self.env = env\n",
        "        self.building_id = env.building_id if hasattr(env, 'building_id') else 0\n",
        "        self.graph_x = torch.zeros((len(env.buildings), 3), dtype=torch.float32)\n",
        "        self.edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "        self.edge_attr = torch.empty((0, 1), dtype=torch.float32)\n",
        "        self.gnn1 = GATv2Conv(3, hidden_size, edge_dim=1)\n",
        "        self.gnn2 = GATv2Conv(hidden_size, hidden_size, edge_dim=1)\n",
        "\n",
        "    def update_graph(self):\n",
        "        graph_x, edge_index, edge_attr = build_dynamic_graph(self.env)\n",
        "        self.graph_x = graph_x\n",
        "        self.edge_index = edge_index\n",
        "        self.edge_attr = edge_attr\n",
        "\n",
        "    def forward(self, obs):\n",
        "        batch_size = obs.shape[0]\n",
        "        x = obs.view(batch_size, 12, self.obs_dim).float()\n",
        "        if self.hidden is None or self.hidden[0].shape[1] != batch_size:\n",
        "            h0 = torch.zeros(self.lstm.num_layers, batch_size, self.hidden_size).to(x.device)\n",
        "            c0 = torch.zeros(self.lstm.num_layers, batch_size, self.hidden_size).to(x.device)\n",
        "            self.hidden = (h0, c0)\n",
        "        lstm_out, self.hidden = self.lstm(x, self.hidden)\n",
        "        self.hidden = (self.hidden[0].detach(), self.hidden[1].detach())\n",
        "        lstm_feature = lstm_out[:, -1, :]\n",
        "\n",
        "        gx = self.graph_x.to(x.device)\n",
        "        ei = self.edge_index.to(x.device)\n",
        "        ea = self.edge_attr.to(x.device)\n",
        "        gx = torch.relu(self.gnn1(gx, ei, ea))\n",
        "        gx = torch.relu(self.gnn2(gx, ei, ea))\n",
        "\n",
        "\n",
        "        gnn_feature = gx[self.building_id].unsqueeze(0).expand(batch_size, -1)\n",
        "\n",
        "        return lstm_feature + gnn_feature\n",
        "\n",
        "# ========== Policy ==========\n",
        "class CustomGNNLSTMPolicy(ActorCriticPolicy):\n",
        "    def __init__(self, observation_space, action_space, lr_schedule, env, **kwargs):\n",
        "        super().__init__(\n",
        "            observation_space,\n",
        "            action_space,\n",
        "            lr_schedule,\n",
        "            features_extractor_class=GNN_LSTM_FeatureExtractor,\n",
        "            features_extractor_kwargs={\"env\": env},\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "# ========== Callback ==========\n",
        "class DynamicGraphCallback(BaseCallback):\n",
        "    def __init__(self, verbose=0):\n",
        "        super().__init__(verbose)\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        self.model.policy.features_extractor.update_graph()\n",
        "        return True\n",
        "\n",
        "# ========== Main ==========\n",
        "if __name__ == '__main__':\n",
        "    env = CityLearnEnv(\n",
        "        schema='citylearn_challenge_2022_phase_1',\n",
        "        reward_function=CustomReward,\n",
        "        central_agent=False\n",
        "    )\n",
        "\n",
        "    single_building_env = CityLearnSingleBuildingWrapper(env, building_id=0, seq_len=12)\n",
        "    vec_env = DummyVecEnv([lambda: single_building_env])\n",
        "\n",
        "    model = PPO(\n",
        "        CustomGNNLSTMPolicy,\n",
        "        vec_env,\n",
        "        normalize_advantage=True,\n",
        "        verbose=1,\n",
        "        n_steps=1024,\n",
        "        batch_size=64,\n",
        "        learning_rate=3e-4,\n",
        "        gamma=0.99,\n",
        "        gae_lambda=0.95,\n",
        "        ent_coef=0.01,\n",
        "        vf_coef=0.4,\n",
        "        max_grad_norm=0.5,\n",
        "        policy_kwargs={\"env\": env}\n",
        "    )\n",
        "\n",
        "    model.policy.features_extractor.update_graph()\n",
        "\n",
        "    eval_env = DummyVecEnv([\n",
        "        lambda: Monitor(CityLearnSingleBuildingWrapper(env, building_id=0, seq_len=12))\n",
        "    ])\n",
        "    eval_callback = EvalCallback(\n",
        "        eval_env,\n",
        "        best_model_save_path=\"./logs/best_model\",\n",
        "        log_path=\"./logs/eval\",\n",
        "        eval_freq=1024,\n",
        "        deterministic=True,\n",
        "        render=False\n",
        "    )\n",
        "\n",
        "    model.learn(total_timesteps=500_000, callback=[DynamicGraphCallback(), eval_callback])\n",
        "    model.save(\"ppo_gnn_lstm_dynamic_graph\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iKxqIlAY_7ei",
        "outputId": "522efbe9-3651-4127-a126-c06441612a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Eval num_timesteps=1024, episode_reward=-2936.11 +/- 0.00\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 8.76e+03  |\n",
            "|    mean_reward     | -2.94e+03 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1024      |\n",
            "----------------------------------\n",
            "New best mean reward!\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1    |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 696  |\n",
            "|    total_timesteps | 1024 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=2048, episode_reward=-993.82 +/- 0.20\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -994         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 2048         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021014106 |\n",
            "|    clip_fraction        | 0.00859      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0.0934       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.14         |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00269     |\n",
            "|    std                  | 0.993        |\n",
            "|    value_loss           | 5.41         |\n",
            "------------------------------------------\n",
            "New best mean reward!\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1    |\n",
            "|    iterations      | 2    |\n",
            "|    time_elapsed    | 1406 |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=3072, episode_reward=-734.26 +/- 0.00\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 8.76e+03    |\n",
            "|    mean_reward          | -734        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 3072        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005945214 |\n",
            "|    clip_fraction        | 0.0479      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | 0.479       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.46        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00771    |\n",
            "|    std                  | 0.991       |\n",
            "|    value_loss           | 5.14        |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1    |\n",
            "|    iterations      | 3    |\n",
            "|    time_elapsed    | 2107 |\n",
            "|    total_timesteps | 3072 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=4096, episode_reward=-1019.18 +/- 0.00\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 8.76e+03    |\n",
            "|    mean_reward          | -1.02e+03   |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006901043 |\n",
            "|    clip_fraction        | 0.0694      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | 0.496       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.56        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00727    |\n",
            "|    std                  | 0.989       |\n",
            "|    value_loss           | 5.02        |\n",
            "-----------------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1    |\n",
            "|    iterations      | 4    |\n",
            "|    time_elapsed    | 2802 |\n",
            "|    total_timesteps | 4096 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=5120, episode_reward=-833.43 +/- 0.00\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 8.76e+03   |\n",
            "|    mean_reward          | -833       |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 5120       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00323179 |\n",
            "|    clip_fraction        | 0.0205     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.41      |\n",
            "|    explained_variance   | 0.566      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.16       |\n",
            "|    n_updates            | 40         |\n",
            "|    policy_gradient_loss | -0.00428   |\n",
            "|    std                  | 0.99       |\n",
            "|    value_loss           | 3.35       |\n",
            "----------------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1    |\n",
            "|    iterations      | 5    |\n",
            "|    time_elapsed    | 3506 |\n",
            "|    total_timesteps | 5120 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=6144, episode_reward=-859.22 +/- 0.12\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -859         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037699568 |\n",
            "|    clip_fraction        | 0.0262       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.627        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.24         |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.00609     |\n",
            "|    std                  | 0.993        |\n",
            "|    value_loss           | 2.53         |\n",
            "------------------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1    |\n",
            "|    iterations      | 6    |\n",
            "|    time_elapsed    | 4206 |\n",
            "|    total_timesteps | 6144 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=7168, episode_reward=-807.13 +/- 0.12\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -807         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 7168         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043685017 |\n",
            "|    clip_fraction        | 0.0268       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.629        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.03         |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.00564     |\n",
            "|    std                  | 0.987        |\n",
            "|    value_loss           | 2.69         |\n",
            "------------------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1    |\n",
            "|    iterations      | 7    |\n",
            "|    time_elapsed    | 4916 |\n",
            "|    total_timesteps | 7168 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=8192, episode_reward=-661.72 +/- 0.00\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -662         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051530483 |\n",
            "|    clip_fraction        | 0.031        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.637        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.871        |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.00658     |\n",
            "|    std                  | 0.993        |\n",
            "|    value_loss           | 2.69         |\n",
            "------------------------------------------\n",
            "New best mean reward!\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1    |\n",
            "|    iterations      | 8    |\n",
            "|    time_elapsed    | 5624 |\n",
            "|    total_timesteps | 8192 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=9216, episode_reward=-646.42 +/- 0.00\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -646         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 9216         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054581454 |\n",
            "|    clip_fraction        | 0.0307       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.624        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.74         |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -0.00379     |\n",
            "|    std                  | 0.988        |\n",
            "|    value_loss           | 3.28         |\n",
            "------------------------------------------\n",
            "New best mean reward!\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1    |\n",
            "|    iterations      | 9    |\n",
            "|    time_elapsed    | 6328 |\n",
            "|    total_timesteps | 9216 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=10240, episode_reward=-680.01 +/- 0.00\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 8.76e+03    |\n",
            "|    mean_reward          | -680        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007267614 |\n",
            "|    clip_fraction        | 0.0648      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.4        |\n",
            "|    explained_variance   | 0.682       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.37        |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.011      |\n",
            "|    std                  | 0.979       |\n",
            "|    value_loss           | 2.64        |\n",
            "-----------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 1     |\n",
            "|    iterations      | 10    |\n",
            "|    time_elapsed    | 7045  |\n",
            "|    total_timesteps | 10240 |\n",
            "------------------------------\n",
            "Eval num_timesteps=11264, episode_reward=-734.46 +/- 0.06\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 8.76e+03    |\n",
            "|    mean_reward          | -734        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 11264       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006147336 |\n",
            "|    clip_fraction        | 0.0376      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.4        |\n",
            "|    explained_variance   | 0.693       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.51        |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.00452    |\n",
            "|    std                  | 0.987       |\n",
            "|    value_loss           | 2.65        |\n",
            "-----------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 1     |\n",
            "|    iterations      | 11    |\n",
            "|    time_elapsed    | 7751  |\n",
            "|    total_timesteps | 11264 |\n",
            "------------------------------\n",
            "Eval num_timesteps=12288, episode_reward=-781.62 +/- 0.02\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -782         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 12288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0062139444 |\n",
            "|    clip_fraction        | 0.0517       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.708        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.941        |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.00649     |\n",
            "|    std                  | 0.988        |\n",
            "|    value_loss           | 2.67         |\n",
            "------------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 1     |\n",
            "|    iterations      | 12    |\n",
            "|    time_elapsed    | 8460  |\n",
            "|    total_timesteps | 12288 |\n",
            "------------------------------\n",
            "Eval num_timesteps=13312, episode_reward=-870.08 +/- 0.02\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 8.76e+03    |\n",
            "|    mean_reward          | -870        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 13312       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007962313 |\n",
            "|    clip_fraction        | 0.104       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | 0.709       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.576       |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.00477    |\n",
            "|    std                  | 0.992       |\n",
            "|    value_loss           | 2.58        |\n",
            "-----------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 1     |\n",
            "|    iterations      | 13    |\n",
            "|    time_elapsed    | 9175  |\n",
            "|    total_timesteps | 13312 |\n",
            "------------------------------\n",
            "Eval num_timesteps=14336, episode_reward=-872.69 +/- 0.03\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -873         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051853782 |\n",
            "|    clip_fraction        | 0.0365       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.72         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.11         |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | -0.00595     |\n",
            "|    std                  | 0.994        |\n",
            "|    value_loss           | 2.53         |\n",
            "------------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 1     |\n",
            "|    iterations      | 14    |\n",
            "|    time_elapsed    | 9888  |\n",
            "|    total_timesteps | 14336 |\n",
            "------------------------------\n",
            "Eval num_timesteps=15360, episode_reward=-838.12 +/- 0.00\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -838         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 15360        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0077824127 |\n",
            "|    clip_fraction        | 0.0482       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.746        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.844        |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -0.00334     |\n",
            "|    std                  | 0.993        |\n",
            "|    value_loss           | 2.51         |\n",
            "------------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 1     |\n",
            "|    iterations      | 15    |\n",
            "|    time_elapsed    | 10615 |\n",
            "|    total_timesteps | 15360 |\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-5-3089795798.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    213\u001b[0m     )\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500_000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDynamicGraphCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ppo_gnn_lstm_dynamic_graph\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     ) -> SelfPPO:\n\u001b[0;32m--> 315\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    316\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# Give access to local variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_locals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/callbacks.py\u001b[0m in \u001b[0;36mon_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/callbacks.py\u001b[0m in \u001b[0;36m_on_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;31m# Return False (stop training) if at least one callback returns False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/callbacks.py\u001b[0m in \u001b[0;36mon_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/callbacks.py\u001b[0m in \u001b[0;36m_on_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_success_buffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m             episode_rewards, episode_lengths = evaluate_policy(\n\u001b[0m\u001b[1;32m    461\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_env\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py\u001b[0m in \u001b[0;36mevaluate_policy\u001b[0;34m(model, env, n_eval_episodes, deterministic, render, callback, reward_threshold, return_episode_rewards, warn)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         )\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mnew_observations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mcurrent_rewards\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mcurrent_lengths\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \"\"\"\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Avoid circular imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/monitor.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tried to step environment that needs reset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mterminated\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-5-3089795798.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_buildings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilding_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilding_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/citylearn/citylearn.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbuilding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuilding_actions\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuildings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m             \u001b[0mbuilding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbuilding_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/citylearn/building.py\u001b[0m in \u001b[0;36mapply_actions\u001b[0;34m(self, cooling_or_heating_device_action, cooling_device_action, heating_device_action, cooling_storage_action, heating_storage_action, dhw_storage_action, electrical_storage_action, electric_vehicle_storage_actions)\u001b[0m\n\u001b[1;32m   1142\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1144\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_cooling_demand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/citylearn/building.py\u001b[0m in \u001b[0;36mupdate_variables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2081\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melectric_vehicle_chargers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2083\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melectric_vehicle_chargers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2084\u001b[0m                 \u001b[0mbuilding_chargers_total_electricity_consumption\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2085\u001b[0m                     \u001b[0mbuilding_chargers_total_electricity_consumption\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melectricity_consumption\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_step\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/citylearn/building.py\u001b[0m in \u001b[0;36melectric_vehicle_chargers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0melectric_vehicle_chargers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCharger\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;34m\"\"\"Electric Vehicle Chargers associated with the building for charging connected eletric vehicles.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "\n",
        "eval_data_path = '/content/logs/eval/evaluations.npz'\n",
        "\n",
        "try:\n",
        "\n",
        "    data = np.load(eval_data_path)\n",
        "\n",
        "    timesteps = data['timesteps']\n",
        "    results = data['results']\n",
        "\n",
        "    mean_rewards = np.mean(results, axis=1)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(timesteps, mean_rewards, label='Mean Evaluation Reward')\n",
        "    plt.title('Agent Performance During Training (Evaluation Callback)')\n",
        "    plt.xlabel('Timesteps')\n",
        "    plt.ylabel('Mean Reward')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"✅ Loaded {len(timesteps)} evaluation points.\")\n",
        "    print(f\"First 5 timesteps: {timesteps[:5]}\")\n",
        "    print(f\"First 5 mean rewards: {mean_rewards[:5]}\")\n",
        "    print(f\"Shape of 'results' array: {results.shape}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"❌ Error: evaluations.npz not found at {eval_data_path}\")\n",
        "    print(\"Please ensure the path is correct and the EvalCallback was configured to save this file.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ An unexpected error occurred: {e}\")\n",
        "    print(f\"Keys available in npz: {list(data.keys())}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "Q31iG3uPa4ky",
        "outputId": "3f2dec37-2265-4525-d15c-0b7076255abc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded 15 evaluation points.\n",
            "First 5 timesteps: [1024 2048 3072 4096 5120]\n",
            "First 5 mean rewards: [-2936.1099152  -993.8173378  -734.2564848 -1019.1838616  -833.432332 ]\n",
            "Shape of 'results' array: (15, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Анализа на графикот од евалуацијата на агентот со GNN**\n",
        "Графикот прикажува како се менува просечната награда за време на тренингот на PPO агентот со GNN + LSTM архитектура. Евалуацијата е правена периодично на одредени timesteps.\n",
        "\n",
        "\n",
        "*  На почетокот (1.000 timesteps), агентот има многу ниска награда (~ -2900), што е очекувано за неиницијализирана политика.\n",
        "*   Брзо се постигнува значително подобрување до околу 3.000 timesteps, каде наградата достигнува ниво над -800. Ова укажува на ефективно иницијално учење.\n",
        "*   Во текот на следните интервали, агентот одржува релативно стабилна награда помеѓу -800 и -1000.\n",
        "*   Нема големи осцилации, но се забележува блага стагнација по 9.000 timesteps.\n",
        "*   На крајот, тренирањето е прекинато на ~15.000 timesteps, при што агентот се наоѓа на најстабилното и најдобро ниво постигнато досега.\n",
        "\n",
        "➡️ Заклучок:\n",
        "Графикот покажува дека архитектурата со GNN има потенцијал за брзо и стабилно учење. Иако нема континуиран пораст, постигната е добра стабилност на наградата. Поради ограничени ресурси и време, тренингот е прекинат на најдобриот досега резултат."
      ],
      "metadata": {
        "id": "RgwZkoS6eshE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "env = CityLearnEnv(\n",
        "    schema='citylearn_challenge_2022_phase_1',\n",
        "    reward_function=CustomReward,\n",
        "    central_agent=False\n",
        ")\n",
        "\n",
        "test_building_id = 2\n",
        "eval_env = CityLearnSingleBuildingWrapper(env, building_id=test_building_id, seq_len=12)\n",
        "\n",
        "model = PPO.load(\"best_model.zip\")\n",
        "\n",
        "obs, _ = eval_env.reset()\n",
        "done = False\n",
        "total_reward = 0\n",
        "\n",
        "while not done:\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, _, _ = eval_env.step(action)\n",
        "    total_reward += reward\n",
        "\n",
        "print(f\"📊 Total reward on unseen building {test_building_id}: {total_reward:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOcFFXyoTKUU",
        "outputId": "e17a778c-83bd-43f0-c12f-c0a4c6059585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Total reward on unseen building 2: -138.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "env = CityLearnEnv(\n",
        "    schema='citylearn_challenge_2022_phase_1',\n",
        "    reward_function=CustomReward,\n",
        "    central_agent=False\n",
        ")\n",
        "\n",
        "test_building_id = 4\n",
        "eval_env = CityLearnSingleBuildingWrapper(env, building_id=test_building_id, seq_len=12)\n",
        "\n",
        "model = PPO.load(\"best_model.zip\")\n",
        "\n",
        "obs, _ = eval_env.reset()\n",
        "done = False\n",
        "total_reward = 0\n",
        "\n",
        "while not done:\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, _, _ = eval_env.step(action)\n",
        "    total_reward += reward\n",
        "\n",
        "print(f\"📊 Total reward on unseen building {test_building_id}: {total_reward:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5Q9J3H3te13",
        "outputId": "6952ceaa-2c5d-4a33-ed9a-3b40a1aa3123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Total reward on unseen building 4: -579.69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "env = CityLearnEnv(\n",
        "    schema='citylearn_challenge_2022_phase_1',\n",
        "    reward_function=CustomReward,\n",
        "    central_agent=False\n",
        ")\n",
        "\n",
        "test_building_id = 1\n",
        "eval_env = CityLearnSingleBuildingWrapper(env, building_id=test_building_id, seq_len=12)\n",
        "\n",
        "model = PPO.load(\"best_model.zip\")\n",
        "\n",
        "obs, _ = eval_env.reset()\n",
        "done = False\n",
        "total_reward = 0\n",
        "\n",
        "while not done:\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, _, _ = eval_env.step(action)\n",
        "    total_reward += reward\n",
        "\n",
        "print(f\"📊 Total reward on unseen building {test_building_id}: {total_reward:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiP_dtNHvera",
        "outputId": "30973938-a74d-4b2a-9788-34f3e2aa24c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Total reward on unseen building 1: -903.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "env = CityLearnEnv(\n",
        "    schema='citylearn_challenge_2022_phase_1',\n",
        "    reward_function=CustomReward,\n",
        "    central_agent=False\n",
        ")\n",
        "\n",
        "test_building_id = 3\n",
        "eval_env = CityLearnSingleBuildingWrapper(env, building_id=test_building_id, seq_len=12)\n",
        "\n",
        "model = PPO.load(\"best_model.zip\")\n",
        "\n",
        "obs, _ = eval_env.reset()\n",
        "done = False\n",
        "total_reward = 0\n",
        "\n",
        "while not done:\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, _, _ = eval_env.step(action)\n",
        "    total_reward += reward\n",
        "\n",
        "print(f\"📊 Total reward on unseen building {test_building_id}: {total_reward:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMBz_JAQvhn9",
        "outputId": "b020b19b-2090-4c3b-eae2-ba477035c933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Total reward on unseen building 3: -625.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🏢 **Евалуација на агентот со GNN на непознати згради**\n",
        "\n",
        "По тренирањето на агентот со GNN + LSTM архитектура на дел од згради во мрежата, истиот агент е тестиран на **неевидени згради** (од истата симулирана околина) со цел да се провери способноста за **генерализација на научената политика**.\n",
        "\n",
        "#### 📋 Резултати од евалуацијата:\n",
        "\n",
        "| ID на зграда | Вкупна награда |\n",
        "|--------------|----------------|\n",
        "| Зграда 2     | -138.24        |\n",
        "| Зграда 4     | -579.69        |\n",
        "| Зграда 1     | -903.35        |\n",
        "| Зграда 3     | -625.10        |\n",
        "\n",
        "---\n",
        "\n",
        "### 🔍 **Анализа:**\n",
        "\n",
        "- ✅ Најдобра изведба е постигната на **зграда 2** со награда од -138.24, што укажува на добро пренесување на наученото од тренинг згради кон нови услови.\n",
        "- 📉 Остатокот од зградите имаат значително пониски резултати, со најлоша изведба на **зграда 1** (-903.35).\n",
        "- Ова покажува дека агентот не се пренесува подеднакво добро на сите згради – најверојатно поради разлики во динамиките, профилите на потрошувачка или недоволно застапена структура на тие згради при тренинг.\n",
        "-  И покрај тоа, GNN модулот очигледно придонесува за подобра **адаптација**, бидејќи дури и на непознати згради се постигнува солиден резултат (значително подобар од почетната награда на тренингот).\n",
        "\n",
        "📌 Ова е важен чекор во анализа на **генерализациската способност** на агентот и посочува каде може да се подобри архитектурата, reward функцијата или граф структурите.\n"
      ],
      "metadata": {
        "id": "bWnWDedohVP9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Архитектура 2: PPO + LSTM (без граф)**"
      ],
      "metadata": {
        "id": "pl23DAGGpNyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch_geometric.nn import GATv2Conv\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from gymnasium import Env, spaces\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
        "from stable_baselines3.common.policies import ActorCriticPolicy\n",
        "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback\n",
        "from citylearn.citylearn import CityLearnEnv\n",
        "from citylearn.reward_function import RewardFunction\n",
        "\n",
        "\n",
        "\n",
        "# ========== Env Wrapper ==========\n",
        "class CityLearnSingleBuildingWrapper(Env):\n",
        "    def __init__(self, env, building_id=0, seq_len=12):\n",
        "        super().__init__()\n",
        "        self.env = env\n",
        "        self.building_id = building_id\n",
        "        self.seq_len = seq_len\n",
        "        self.n_buildings = len(env.action_space)\n",
        "        self.obs_dim = env.observation_space[building_id].shape[0]\n",
        "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(seq_len * self.obs_dim,), dtype=np.float32)\n",
        "        self.buffer = []\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        obs, _ = self.env.reset(**kwargs)\n",
        "        self.buffer = []\n",
        "        o = obs[self.building_id]\n",
        "        for _ in range(self.seq_len):\n",
        "            self.buffer.append(o)\n",
        "        return np.concatenate(self.buffer), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        actions = [[0.0] * self.env.action_space[0].shape[0] for _ in range(self.n_buildings)]\n",
        "        actions[self.building_id] = [float(action[0])]\n",
        "        obs, reward, done, trunc, info = self.env.step(actions)\n",
        "        o = obs[self.building_id]\n",
        "        self.buffer.pop(0)\n",
        "        self.buffer.append(o)\n",
        "        return np.concatenate(self.buffer), reward[self.building_id], done, trunc, info\n",
        "\n",
        "# ========== Feature Extractor ==========\n",
        "class LSTM_FeatureExtractor(BaseFeaturesExtractor):\n",
        "    def __init__(self, observation_space, hidden_size=64, lstm_layers=1):\n",
        "        super().__init__(observation_space, features_dim=hidden_size)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.obs_dim = observation_space.shape[0] // 12\n",
        "        self.lstm = nn.LSTM(self.obs_dim, hidden_size, lstm_layers, batch_first=True)\n",
        "        self.hidden = None\n",
        "\n",
        "    def forward(self, obs):\n",
        "        batch_size = obs.shape[0]\n",
        "        x = obs.view(batch_size, 12, self.obs_dim).float()\n",
        "        if self.hidden is None or self.hidden[0].shape[1] != batch_size:\n",
        "            h0 = torch.zeros(self.lstm.num_layers, batch_size, self.hidden_size).to(x.device)\n",
        "            c0 = torch.zeros(self.lstm.num_layers, batch_size, self.hidden_size).to(x.device)\n",
        "            self.hidden = (h0, c0)\n",
        "        lstm_out, self.hidden = self.lstm(x, self.hidden)\n",
        "        self.hidden = (self.hidden[0].detach(), self.hidden[1].detach())\n",
        "        lstm_feature = lstm_out[:, -1, :]\n",
        "        return lstm_feature\n",
        "\n",
        "# ========== Policy ==========\n",
        "class CustomLSTMPolicy(ActorCriticPolicy):\n",
        "    def __init__(self, observation_space, action_space, lr_schedule, **kwargs):\n",
        "        super().__init__(\n",
        "            observation_space,\n",
        "            action_space,\n",
        "            lr_schedule,\n",
        "            features_extractor_class=LSTM_FeatureExtractor,\n",
        "            features_extractor_kwargs={},\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "# ========== Callback ==========\n",
        "class EvalCallbackWrapper(BaseCallback):\n",
        "    def __init__(self, verbose=0):\n",
        "        super().__init__(verbose)\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        return True\n",
        "\n",
        "# ========== Main ==========\n",
        "if __name__ == '__main__':\n",
        "    env = CityLearnEnv(\n",
        "        schema='citylearn_challenge_2022_phase_1',\n",
        "        reward_function=CustomReward,\n",
        "        central_agent=False\n",
        "    )\n",
        "\n",
        "    single_building_env = CityLearnSingleBuildingWrapper(env, building_id=0, seq_len=12)\n",
        "    vec_env = DummyVecEnv([lambda: single_building_env])\n",
        "\n",
        "    model = PPO(\n",
        "        CustomLSTMPolicy,\n",
        "        vec_env,\n",
        "        normalize_advantage=True,\n",
        "        verbose=1,\n",
        "        n_steps=1024,\n",
        "        batch_size=64,\n",
        "        learning_rate=3e-4,\n",
        "        gamma=0.99,\n",
        "        gae_lambda=0.95,\n",
        "        ent_coef=0.01,\n",
        "        vf_coef=0.4,\n",
        "        max_grad_norm=0.5,\n",
        "        policy_kwargs={}\n",
        "    )\n",
        "\n",
        "    eval_env = DummyVecEnv([lambda: Monitor(CityLearnSingleBuildingWrapper(env, building_id=0, seq_len=12))])\n",
        "    eval_callback = EvalCallback(\n",
        "        eval_env,\n",
        "        best_model_save_path=\"./logs/best_model\",\n",
        "        log_path=\"./logs/eval\",\n",
        "        eval_freq=1024,\n",
        "        deterministic=True,\n",
        "        render=False\n",
        "    )\n",
        "\n",
        "    model.learn(total_timesteps=100_000, callback=eval_callback)\n",
        "    model.save(\"ppo_lstm_without_gnn\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XwoMlFgjObwY",
        "outputId": "2090def7-8f06-428a-f2f8-53681e2a825e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Eval num_timesteps=1024, episode_reward=-982.75 +/- 0.16\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 8.76e+03 |\n",
            "|    mean_reward     | -983     |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 1024     |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 2    |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 480  |\n",
            "|    total_timesteps | 1024 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=2048, episode_reward=-2943.35 +/- 0.20\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -2.94e+03    |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 2048         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036795712 |\n",
            "|    clip_fraction        | 0.0319       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.0796       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.49         |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00596     |\n",
            "|    std                  | 0.981        |\n",
            "|    value_loss           | 5.31         |\n",
            "------------------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 2    |\n",
            "|    iterations      | 2    |\n",
            "|    time_elapsed    | 966  |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=3072, episode_reward=-459.35 +/- 0.00\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -459         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 3072         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0062982533 |\n",
            "|    clip_fraction        | 0.0554       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.4         |\n",
            "|    explained_variance   | 0.452        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.39         |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00722     |\n",
            "|    std                  | 0.977        |\n",
            "|    value_loss           | 5.92         |\n",
            "------------------------------------------\n",
            "New best mean reward!\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 2    |\n",
            "|    iterations      | 3    |\n",
            "|    time_elapsed    | 1447 |\n",
            "|    total_timesteps | 3072 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=4096, episode_reward=-987.33 +/- 0.00\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -987         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059022647 |\n",
            "|    clip_fraction        | 0.0512       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.4         |\n",
            "|    explained_variance   | 0.493        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.44         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00685     |\n",
            "|    std                  | 0.981        |\n",
            "|    value_loss           | 4.72         |\n",
            "------------------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 2    |\n",
            "|    iterations      | 4    |\n",
            "|    time_elapsed    | 1919 |\n",
            "|    total_timesteps | 4096 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=5120, episode_reward=-791.10 +/- 0.06\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -791         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 5120         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023515173 |\n",
            "|    clip_fraction        | 0.00713      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.4         |\n",
            "|    explained_variance   | 0.608        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.836        |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00384     |\n",
            "|    std                  | 0.988        |\n",
            "|    value_loss           | 2.95         |\n",
            "------------------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 2    |\n",
            "|    iterations      | 5    |\n",
            "|    time_elapsed    | 2396 |\n",
            "|    total_timesteps | 5120 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=6144, episode_reward=-836.51 +/- 0.01\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -837         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034208682 |\n",
            "|    clip_fraction        | 0.0246       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.604        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.802        |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.00272     |\n",
            "|    std                  | 0.996        |\n",
            "|    value_loss           | 3.05         |\n",
            "------------------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 2    |\n",
            "|    iterations      | 6    |\n",
            "|    time_elapsed    | 2874 |\n",
            "|    total_timesteps | 6144 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=7168, episode_reward=-951.37 +/- 0.73\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -951         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 7168         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034851942 |\n",
            "|    clip_fraction        | 0.0288       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.575        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.51         |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.00462     |\n",
            "|    std                  | 0.988        |\n",
            "|    value_loss           | 3.82         |\n",
            "------------------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 2    |\n",
            "|    iterations      | 7    |\n",
            "|    time_elapsed    | 3350 |\n",
            "|    total_timesteps | 7168 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=8192, episode_reward=-867.41 +/- 0.20\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -867         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045142155 |\n",
            "|    clip_fraction        | 0.042        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.631        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.35         |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.00603     |\n",
            "|    std                  | 0.993        |\n",
            "|    value_loss           | 3.18         |\n",
            "------------------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 2    |\n",
            "|    iterations      | 8    |\n",
            "|    time_elapsed    | 3818 |\n",
            "|    total_timesteps | 8192 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=9216, episode_reward=-793.05 +/- 0.07\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -793         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 9216         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024925852 |\n",
            "|    clip_fraction        | 0.0133       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0.652        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.659        |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -0.00276     |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 2.94         |\n",
            "------------------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 2    |\n",
            "|    iterations      | 9    |\n",
            "|    time_elapsed    | 4291 |\n",
            "|    total_timesteps | 9216 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=10240, episode_reward=-753.28 +/- 0.02\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -753         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031666846 |\n",
            "|    clip_fraction        | 0.0211       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0.68         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.726        |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.0055      |\n",
            "|    std                  | 0.998        |\n",
            "|    value_loss           | 3.16         |\n",
            "------------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 2     |\n",
            "|    iterations      | 10    |\n",
            "|    time_elapsed    | 4761  |\n",
            "|    total_timesteps | 10240 |\n",
            "------------------------------\n",
            "Eval num_timesteps=11264, episode_reward=-825.93 +/- 0.00\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 8.76e+03    |\n",
            "|    mean_reward          | -826        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 11264       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006815547 |\n",
            "|    clip_fraction        | 0.0437      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.42       |\n",
            "|    explained_variance   | 0.685       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.759       |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.00605    |\n",
            "|    std                  | 0.997       |\n",
            "|    value_loss           | 2.86        |\n",
            "-----------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 2     |\n",
            "|    iterations      | 11    |\n",
            "|    time_elapsed    | 5226  |\n",
            "|    total_timesteps | 11264 |\n",
            "------------------------------\n",
            "Eval num_timesteps=12288, episode_reward=-837.95 +/- 0.00\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -838         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 12288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0067827147 |\n",
            "|    clip_fraction        | 0.0517       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.695        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.705        |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.00623     |\n",
            "|    std                  | 0.993        |\n",
            "|    value_loss           | 2.83         |\n",
            "------------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 2     |\n",
            "|    iterations      | 12    |\n",
            "|    time_elapsed    | 5691  |\n",
            "|    total_timesteps | 12288 |\n",
            "------------------------------\n",
            "Eval num_timesteps=13312, episode_reward=-820.61 +/- 0.11\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -821         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 13312        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059177894 |\n",
            "|    clip_fraction        | 0.0476       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.711        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.24         |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -0.00743     |\n",
            "|    std                  | 0.993        |\n",
            "|    value_loss           | 3.09         |\n",
            "------------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 2     |\n",
            "|    iterations      | 13    |\n",
            "|    time_elapsed    | 6164  |\n",
            "|    total_timesteps | 13312 |\n",
            "------------------------------\n",
            "Eval num_timesteps=14336, episode_reward=-921.18 +/- 0.00\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 8.76e+03    |\n",
            "|    mean_reward          | -921        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005115837 |\n",
            "|    clip_fraction        | 0.0479      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | 0.763       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.821       |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.00391    |\n",
            "|    std                  | 0.987       |\n",
            "|    value_loss           | 2.26        |\n",
            "-----------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 2     |\n",
            "|    iterations      | 14    |\n",
            "|    time_elapsed    | 6654  |\n",
            "|    total_timesteps | 14336 |\n",
            "------------------------------\n",
            "Eval num_timesteps=15360, episode_reward=-841.98 +/- 0.00\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 8.76e+03    |\n",
            "|    mean_reward          | -842        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 15360       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006164441 |\n",
            "|    clip_fraction        | 0.0647      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | 0.729       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.08        |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.0054     |\n",
            "|    std                  | 0.996       |\n",
            "|    value_loss           | 3.35        |\n",
            "-----------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 2     |\n",
            "|    iterations      | 15    |\n",
            "|    time_elapsed    | 7130  |\n",
            "|    total_timesteps | 15360 |\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4278422968.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m     )\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100_000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ppo_lstm_without_gnn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     ) -> SelfPPO:\n\u001b[0;32m--> 315\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    316\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# Give access to local variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_locals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/callbacks.py\u001b[0m in \u001b[0;36mon_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/callbacks.py\u001b[0m in \u001b[0;36m_on_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_success_buffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m             episode_rewards, episode_lengths = evaluate_policy(\n\u001b[0m\u001b[1;32m    461\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_env\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py\u001b[0m in \u001b[0;36mevaluate_policy\u001b[0;34m(model, env, n_eval_episodes, deterministic, render, callback, reward_threshold, return_episode_rewards, warn)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         )\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mnew_observations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mcurrent_rewards\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mcurrent_lengths\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \"\"\"\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Avoid circular imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/monitor.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tried to step environment that needs reset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mterminated\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4278422968.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_buildings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilding_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilding_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/citylearn/citylearn.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/citylearn/citylearn.py\u001b[0m in \u001b[0;36mobservations\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0mobservations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiodic_normalization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_limits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuildings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobservations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/citylearn/citylearn.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0mobservations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiodic_normalization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_limits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuildings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobservations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/citylearn/building.py\u001b[0m in \u001b[0;36mobservations\u001b[0;34m(self, include_all, normalize, periodic_normalization, check_limits)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mobservations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_observations_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minclude_all\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/citylearn/building.py\u001b[0m in \u001b[0;36m_get_observations_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    999\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdhw_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHeatPump\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdhw_device\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mefficiency\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m             \u001b[0;34m'indoor_dry_bulb_temperature_cooling_set_point'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menergy_simulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindoor_dry_bulb_temperature_cooling_set_point\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m             \u001b[0;34m'indoor_dry_bulb_temperature_heating_set_point'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menergy_simulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindoor_dry_bulb_temperature_heating_set_point\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m             \u001b[0;34m'indoor_dry_bulb_temperature_cooling_delta'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menergy_simulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindoor_dry_bulb_temperature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menergy_simulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindoor_dry_bulb_temperature_cooling_set_point\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0;34m'indoor_dry_bulb_temperature_heating_delta'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menergy_simulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindoor_dry_bulb_temperature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menergy_simulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindoor_dry_bulb_temperature_heating_set_point\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/citylearn/data.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name, start_time_step, end_time_step)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'_{name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m             \u001b[0mstart_time_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_time_step\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstart_time_step\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstart_time_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mstart_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstart_time_step\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstart_time_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/typing.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__instancecheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/typing.py\u001b[0m in \u001b[0;36m__subclasscheck__\u001b[0;34m(self, cls)\u001b[0m\n\u001b[1;32m   1604\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__origin__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__origin__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_GenericAlias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1606\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__origin__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1607\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/abc.py\u001b[0m in \u001b[0;36m__subclasscheck__\u001b[0;34m(cls, subclass)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "\n",
        "eval_data_path = '/content/logs/eval/evaluations.npz'\n",
        "\n",
        "try:\n",
        "\n",
        "    data = np.load(eval_data_path)\n",
        "\n",
        "\n",
        "    timesteps = data['timesteps']\n",
        "    results = data['results']\n",
        "\n",
        "\n",
        "    mean_rewards = np.mean(results, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(timesteps, mean_rewards, label='Mean Evaluation Reward')\n",
        "    plt.title('Agent Performance During Training (Evaluation Callback)')\n",
        "    plt.xlabel('Timesteps')\n",
        "    plt.ylabel('Mean Reward')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"✅ Loaded {len(timesteps)} evaluation points.\")\n",
        "    print(f\"First 5 timesteps: {timesteps[:5]}\")\n",
        "    print(f\"First 5 mean rewards: {mean_rewards[:5]}\")\n",
        "    print(f\"Shape of 'results' array: {results.shape}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"❌ Error: evaluations.npz not found at {eval_data_path}\")\n",
        "    print(\"Please ensure the path is correct and the EvalCallback was configured to save this file.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ An unexpected error occurred: {e}\")\n",
        "    print(f\"Keys available in npz: {list(data.keys())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "W4C_hKSRrkpo",
        "outputId": "41a2e43c-f41a-43cd-99b0-c8fb46175aeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded 15 evaluation points.\n",
            "First 5 timesteps: [1024 2048 3072 4096 5120]\n",
            "First 5 mean rewards: [ -982.7511896 -2943.3508958  -459.354332   -987.3349214  -791.0975352]\n",
            "Shape of 'results' array: (15, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📉 **Анализа на евалуацијата на агентот без GNN**\n",
        "\n",
        "Овој график ја прикажува промената на просечната награда во текот на тренингот на PPO агентот кој користи само **LSTM архитектура**, без Graph Neural Network (GNN) модул.\n",
        "\n",
        "#### 📌 Клучни точки од графикот:\n",
        "\n",
        "- 🟡 На самиот почеток (помеѓу 1000–2000 timesteps) се забележува **драстичен пад** на наградата, достигнувајќи вредност блиска до -3000. Ова укажува на нестабилен старт и неефикасна иницијална политика.\n",
        "- 🟢 Потоа следува **нагло подобрување**, каде агентот успева да достигне награда подобра од -500.\n",
        "- 🔁 Од тој момент, резултатите покажуваат **флуктуации и нестабилност**, без конзистентен напредок. Наградата варира околу -800 до -1000, со благи осцилации.\n",
        "- ⏹️ Тренингот е запрен на ~15.000 timesteps при релативно стабилна, но **неоптимизирана** состојба.\n",
        "\n",
        "---\n",
        "\n",
        "###  Забелешка:\n",
        "\n",
        "Иако агентот без GNN успева да се стабилизира по лошиот старт, неговото учење е пофлуктуирачко и нестабилно во споредба со очекувањата. Ова сугерира дека без дополнителен контекст (како оној што го дава графот), агентот има потешкотии да постигне доследни резултати низ различни временски интервали од тренингот.\n"
      ],
      "metadata": {
        "id": "CITbM-NEiI_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "env = CityLearnEnv(\n",
        "    schema='citylearn_challenge_2022_phase_1',\n",
        "    reward_function=CustomReward,\n",
        "    central_agent=False\n",
        ")\n",
        "\n",
        "test_building_id = 2  # пробај со друга зграда\n",
        "eval_env = CityLearnSingleBuildingWrapper(env, building_id=test_building_id, seq_len=12)\n",
        "\n",
        "model = PPO.load(\"best_model_without_GNN_400.zip\")\n",
        "\n",
        "obs, _ = eval_env.reset()\n",
        "done = False\n",
        "total_reward = 0\n",
        "\n",
        "while not done:\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, _, _ = eval_env.step(action)\n",
        "    total_reward += reward\n",
        "\n",
        "print(f\"📊 Total reward on unseen building {test_building_id}: {total_reward:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfrA8dJyryHb",
        "outputId": "7c6280cc-12d3-4780-cc3b-da543475022f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Total reward on unseen building 2: 144.36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "env = CityLearnEnv(\n",
        "    schema='citylearn_challenge_2022_phase_1',\n",
        "    reward_function=CustomReward,\n",
        "    central_agent=False\n",
        ")\n",
        "\n",
        "test_building_id = 4  # пробај со друга зграда\n",
        "eval_env = CityLearnSingleBuildingWrapper(env, building_id=test_building_id, seq_len=12)\n",
        "\n",
        "model = PPO.load(\"best_model_without_GNN_400.zip\")\n",
        "\n",
        "obs, _ = eval_env.reset()\n",
        "done = False\n",
        "total_reward = 0\n",
        "\n",
        "while not done:\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, _, _ = eval_env.step(action)\n",
        "    total_reward += reward\n",
        "\n",
        "print(f\"📊 Total reward on unseen building {test_building_id}: {total_reward:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4ux5RnpsZdh",
        "outputId": "ec3d843d-0e35-4d34-d5b9-a238d3cc3c30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Total reward on unseen building 4: -319.77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "env = CityLearnEnv(\n",
        "    schema='citylearn_challenge_2022_phase_1',\n",
        "    reward_function=CustomReward,\n",
        "    central_agent=False\n",
        ")\n",
        "\n",
        "test_building_id = 1  # пробај со друга зграда\n",
        "eval_env = CityLearnSingleBuildingWrapper(env, building_id=test_building_id, seq_len=12)\n",
        "\n",
        "model = PPO.load(\"best_model_without_GNN_400.zip\")\n",
        "\n",
        "obs, _ = eval_env.reset()\n",
        "done = False\n",
        "total_reward = 0\n",
        "\n",
        "while not done:\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, _, _ = eval_env.step(action)\n",
        "    total_reward += reward\n",
        "\n",
        "print(f\"📊 Total reward on unseen building {test_building_id}: {total_reward:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sweyzA-1u60P",
        "outputId": "0398cd0f-3961-4424-da46-67f30e64ac51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Total reward on unseen building 1: -675.46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "env = CityLearnEnv(\n",
        "    schema='citylearn_challenge_2022_phase_1',\n",
        "    reward_function=CustomReward,\n",
        "    central_agent=False\n",
        ")\n",
        "\n",
        "test_building_id = 3  # пробај со друга зграда\n",
        "eval_env = CityLearnSingleBuildingWrapper(env, building_id=test_building_id, seq_len=12)\n",
        "\n",
        "model = PPO.load(\"best_model_without_GNN_400.zip\")\n",
        "\n",
        "obs, _ = eval_env.reset()\n",
        "done = False\n",
        "total_reward = 0\n",
        "\n",
        "while not done:\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, _, _ = eval_env.step(action)\n",
        "    total_reward += reward\n",
        "\n",
        "print(f\"📊 Total reward on unseen building {test_building_id}: {total_reward:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZiXDdE9vAh9",
        "outputId": "8baaea26-eef2-452e-9cc4-0a5df3833cdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Total reward on unseen building 3: -459.38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🏢 **Мислење за евалуацијата на агентот без GNN**\n",
        "\n",
        "Резултатите добиени при тестирање на агентот (без GNN модул) на згради кои не биле вклучени во тренингот се следните:\n",
        "\n",
        "#### 📋 Вкупна награда по зграда:\n",
        "\n",
        "| ID на зграда | Вкупна награда |\n",
        "|--------------|----------------|\n",
        "| Зграда 2     | 144.36 ✅       |\n",
        "| Зграда 4     | -319.77        |\n",
        "| Зграда 1     | -675.46        |\n",
        "| Зграда 3     | -459.38        |\n",
        "\n",
        "---\n",
        "\n",
        "### 💭 **Мислење:**\n",
        "\n",
        "И покрај тоа што **тренингот на овој агент беше релативно нестабилен**, како што може да се види од евалуациониот график, финалната политика сепак успеала да се **пренесе ефективно на нови згради**.\n",
        "\n",
        "- ✅ Посебно се истакнува **позитивниот reward на зграда 2**, што покажува дека агентот успеал не само да избегне казни, туку и да оптимизира енергетско однесување.\n",
        "- 📉 И кај другите згради, иако резултатите се негативни, тие се **во разумни граници** и не се премногу далеку од нула.\n",
        "-  Ова укажува дека дури и без графичка структура, агентот е способен да научи **доволно силна и адаптивна политика**.\n",
        "\n",
        "✨ Вкупниот впечаток е позитивен, бидејќи моделот покажува **корисна генерализациска способност** дури и под услови на нестабилен тренинг.\n"
      ],
      "metadata": {
        "id": "IwJhj99olWDQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ **Крајна споредба и заклучок**\n",
        "\n",
        "Овој експеримент ги споредуваше перформансите на два PPO агента во CityLearn средина:\n",
        "- **Агент со GNN + LSTM архитектура**\n",
        "- **Агент само со LSTM архитектура (без GNN)**\n",
        "\n",
        "### 📈 1. Перформанси за време на тренинг:\n",
        "\n",
        "| Карактеристика          | Со GNN             | Без GNN            |\n",
        "|------------------------|--------------------|---------------------|\n",
        "| Почеток на тренинг     | Многу слаб         | Слаб                |\n",
        "| Подобрување            | Брзо и стабилно    | Брзо, но флуктуира |\n",
        "| Стагнација             | Присутна           | Присутна            |\n",
        "| Финална награда        | ~ -900             | ~ -800              |\n",
        "\n",
        "📌 **Забелешка:** Агентот со GNN има посмирено учење, но не успева да го задржи напредокот на подолг рок. Агентот без GNN има поголеми осцилации, но сличен финален резултат.\n",
        "\n",
        "---\n",
        "\n",
        "### 🏢 2. Евалуација на непознати згради:\n",
        "\n",
        "| Зграда | Reward со GNN | Reward без GNN |\n",
        "|--------|----------------|----------------|\n",
        "| 2      | -138.24        | **+144.36** ✅   |\n",
        "| 4      | -579.69        | **-319.77** ✅   |\n",
        "| 1      | -903.35        | **-675.46** ✅   |\n",
        "| 3      | -625.10        | **-459.38** ✅   |\n",
        "\n",
        "📌 **Забелешка:** Агентот **без GNN постигнува подобри резултати на сите згради**, дури и позитивна награда во еден случај.\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ **Финален заклучок**\n",
        "\n",
        "Врз основа на добиените резултати, може да се заклучи дека:\n",
        "\n",
        "- **Агентот без GNN модул покажува подобра генерализација** кога се тестира на згради кои не биле дел од тренинг околината.\n",
        "- Резултатите на овие непознати згради се подобри во сите случаи, вклучително и постигнување позитивна награда на една од нив.\n",
        "\n",
        "📌 **Сепак, важно е да се истакне** дека оваа споредба е направена под услови на **еднакво траење на тренингот за двата агента**. Можно е агентот со GNN да бара **подолг тренинг** за да ја покаже својата предност, особено поради дополнителната комплексност на архитектурата.\n",
        "\n",
        "🔍 Поради тоа:\n",
        "- Овие резултати **не ја исклучуваат ефективноста на GNN**, туку само укажуваат дека **во дадените услови**, поедноставната архитектура покажала подобра адаптација.\n",
        "- Споредбата отвора простор за понатамошни истражувања, како што се:\n",
        "  - продолжен тренинг на GNN агентот,\n",
        "  - тестирање со различни граф структури,\n",
        "  - комбинирање со други типови reward функции или хиперпараметарска оптимизација.\n",
        "\n",
        "---\n",
        "\n",
        "✨ Заклучокот е дека **агентот без GNN во ова сценарио покажува силна генерализациска способност**, но целосната предност на GNN можеби не е целосно искористена во рамките на тековните ограничувања (време, ресурси, број на чекори).\n",
        "\n"
      ],
      "metadata": {
        "id": "rlXCb0MUl0qk"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}