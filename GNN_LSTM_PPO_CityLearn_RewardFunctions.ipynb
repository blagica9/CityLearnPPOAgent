{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Истражување на влијанието на дизајнот на Reward функција врз перформансите на засилен агент во CityLearn**\n"
      ],
      "metadata": {
        "id": "Fb3ey8IA6LDC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Овој проект истражува како дизајнот на reward функцијата влијае врз учењето и перформансите на централизираниот засилен агент во симулациската околина CityLearn. Се користи архитектура базирана на PPO алгоритам во комбинација со LSTM и GNN, при што графот се ажурира динамички за секој епизоден почеток. Агентот се тренира со две различни reward функции – едноставна и комплексна. Целта е да се процени влијанието на секоја функција врз стабилноста на учењето, финалниот reward и генерализациската способност на агентот на непознати згради.\n"
      ],
      "metadata": {
        "id": "EA18BHMF6a48"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Инсталација на зависности\n"
      ],
      "metadata": {
        "id": "ZB43reBi6hh2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "csrUTkUGWvk4",
        "outputId": "c72338e0-5754-4682-92fc-26ebeacd6d75",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting citylearn==2.3.0\n",
            "  Downloading CityLearn-2.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting doe-xstock>=1.1.0 (from citylearn==2.3.0)\n",
            "  Downloading doe_xstock-1.1.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (from citylearn==2.3.0) (1.2.0)\n",
            "Collecting nrel-pysam (from citylearn==2.3.0)\n",
            "  Downloading nrel_pysam-7.0.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (8.9 kB)\n",
            "Collecting numpy<2.0.0 (from citylearn==2.3.0)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from citylearn==2.3.0) (2.2.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from citylearn==2.3.0) (6.0.2)\n",
            "Collecting scikit-learn<=1.2.2 (from citylearn==2.3.0)\n",
            "  Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.11/dist-packages (from citylearn==2.3.0) (3.20.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from citylearn==2.3.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from citylearn==2.3.0) (0.21.0+cu124)\n",
            "Collecting openstudio<=3.3.0 (from citylearn==2.3.0)\n",
            "  Downloading openstudio-3.3.0-py3-none-manylinux1_x86_64.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from doe-xstock>=1.1.0->citylearn==2.3.0) (4.13.4)\n",
            "Collecting eppy (from doe-xstock>=1.1.0->citylearn==2.3.0)\n",
            "  Downloading eppy-0.5.63-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from doe-xstock>=1.1.0->citylearn==2.3.0) (4.3.8)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from doe-xstock>=1.1.0->citylearn==2.3.0) (18.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from doe-xstock>=1.1.0->citylearn==2.3.0) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<=1.2.2->citylearn==2.3.0) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<=1.2.2->citylearn==2.3.0) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<=1.2.2->citylearn==2.3.0) (3.6.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium->citylearn==2.3.0) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium->citylearn==2.3.0) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium->citylearn==2.3.0) (0.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->citylearn==2.3.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->citylearn==2.3.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->citylearn==2.3.0) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->citylearn==2.3.0) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->citylearn==2.3.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->citylearn==2.3.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->citylearn==2.3.0) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->citylearn==2.3.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->citylearn==2.3.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->citylearn==2.3.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->citylearn==2.3.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->citylearn==2.3.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->citylearn==2.3.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->citylearn==2.3.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->citylearn==2.3.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->citylearn==2.3.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->citylearn==2.3.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->citylearn==2.3.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->citylearn==2.3.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->citylearn==2.3.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->citylearn==2.3.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->citylearn==2.3.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->citylearn==2.3.0) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->citylearn==2.3.0) (11.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->citylearn==2.3.0) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->doe-xstock>=1.1.0->citylearn==2.3.0) (2.7)\n",
            "Collecting munch>=2.0.2 (from eppy->doe-xstock>=1.1.0->citylearn==2.3.0)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting beautifulsoup4 (from doe-xstock>=1.1.0->citylearn==2.3.0)\n",
            "  Downloading beautifulsoup4-4.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting tinynumpy>=1.2.1 (from eppy->doe-xstock>=1.1.0->citylearn==2.3.0)\n",
            "  Downloading tinynumpy-1.2.1.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.11/dist-packages (from eppy->doe-xstock>=1.1.0->citylearn==2.3.0) (4.4.2)\n",
            "Requirement already satisfied: lxml>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from eppy->doe-xstock>=1.1.0->citylearn==2.3.0) (5.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from eppy->doe-xstock>=1.1.0->citylearn==2.3.0) (1.0.0)\n",
            "Collecting pydot3k (from eppy->doe-xstock>=1.1.0->citylearn==2.3.0)\n",
            "  Downloading pydot3k-1.0.17.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyparsing>=2.4.7 in /usr/local/lib/python3.11/dist-packages (from eppy->doe-xstock>=1.1.0->citylearn==2.3.0) (3.2.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->citylearn==2.3.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->doe-xstock>=1.1.0->citylearn==2.3.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->doe-xstock>=1.1.0->citylearn==2.3.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->doe-xstock>=1.1.0->citylearn==2.3.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->doe-xstock>=1.1.0->citylearn==2.3.0) (2025.7.14)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pydot3k->eppy->doe-xstock>=1.1.0->citylearn==2.3.0) (75.2.0)\n",
            "Downloading CityLearn-2.3.0-py3-none-any.whl (379 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.5/379.5 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading doe_xstock-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m116.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openstudio-3.3.0-py3-none-manylinux1_x86_64.whl (61.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m129.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nrel_pysam-7.0.0-cp311-cp311-manylinux2014_x86_64.whl (47.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eppy-0.5.63-py2.py3-none-any.whl (869 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.7/869.7 kB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading beautifulsoup4-4.8.0-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.5/97.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Building wheels for collected packages: tinynumpy, pydot3k\n",
            "  Building wheel for tinynumpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinynumpy: filename=tinynumpy-1.2.1-py3-none-any.whl size=18463 sha256=cdf29363fffbf280d18ce27e94fdde9e0410cfa1dac0c0719634f613bbc46c12\n",
            "  Stored in directory: /root/.cache/pip/wheels/d8/c3/c5/85bd9b13ea6e3c76b0bc39db2b28b7d743a771547bf0fb0bdd\n",
            "  Building wheel for pydot3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pydot3k: filename=pydot3k-1.0.17-py3-none-any.whl size=19038 sha256=0ea8bdffc5c5e3188f950b0600ba1a5cfa59a2dabd6c4b5328b38f4e5f5760b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/df/1f/e1f65a805151fead9e6d9fcbd1441bcf3bba677c4bb6b61059\n",
            "Successfully built tinynumpy pydot3k\n",
            "Installing collected packages: tinynumpy, nrel-pysam, pydot3k, openstudio, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, munch, beautifulsoup4, nvidia-cusparse-cu12, nvidia-cudnn-cu12, eppy, scikit-learn, nvidia-cusolver-cu12, doe-xstock, citylearn\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.13.4\n",
            "    Uninstalling beautifulsoup4-4.13.4:\n",
            "      Successfully uninstalled beautifulsoup4-4.13.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "yfinance 0.2.65 requires beautifulsoup4>=4.11.1, but you have beautifulsoup4 4.8.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "cuml-cu12 25.6.0 requires scikit-learn>=1.5, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "libpysal 4.13.0 requires beautifulsoup4>=4.10, but you have beautifulsoup4 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed beautifulsoup4-4.8.0 citylearn-2.3.0 doe-xstock-1.1.0 eppy-0.5.63 munch-4.0.0 nrel-pysam-7.0.0 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openstudio-3.3.0 pydot3k-1.0.17 scikit-learn-1.2.2 tinynumpy-1.2.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "6fa5a5e8881b4b71a4ab5e4561621b8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: gym 0.25.2\n",
            "Uninstalling gym-0.25.2:\n",
            "  Successfully uninstalled gym-0.25.2\n",
            "Collecting gymnasium==0.29.1\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1) (0.0.4)\n",
            "Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gymnasium\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.2.0\n",
            "    Uninstalling gymnasium-1.2.0:\n",
            "      Successfully uninstalled gymnasium-1.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires gym<=0.25.2, which is not installed.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gymnasium-0.29.1\n",
            "Collecting stable-baselines3==2.2.1 (from stable-baselines3[extra]==2.2.1)\n",
            "  Downloading stable_baselines3-2.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]==2.2.1) (4.12.0.88)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]==2.2.1) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]==2.2.1) (2.18.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]==2.2.1) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]==2.2.1) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]==2.2.1) (13.9.4)\n",
            "Collecting shimmy~=1.3.0 (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]==2.2.1)\n",
            "  Downloading Shimmy-1.3.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]==2.2.1) (11.3.0)\n",
            "Collecting autorom~=0.6.1 (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]==2.2.1)\n",
            "  Downloading AutoROM-0.6.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]==2.2.1) (8.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]==2.2.1) (2.32.3)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]==2.2.1)\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (0.0.4)\n",
            "Collecting ale-py~=0.8.1 (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]==2.2.1)\n",
            "  Downloading ale_py-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]==2.2.1) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]==2.2.1) (1.74.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]==2.2.1) (3.8.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]==2.2.1) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]==2.2.1) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]==2.2.1) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]==2.2.1) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]==2.2.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]==2.2.1) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (2.9.0.post0)\n",
            "Collecting numpy>=1.20 (from stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1)\n",
            "  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3==2.2.1->stable-baselines3[extra]==2.2.1) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]==2.2.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]==2.2.1) (2.19.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]==2.2.1) (6.5.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]==2.2.1) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]==2.2.1) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]==2.2.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]==2.2.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]==2.2.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]==2.2.1) (2025.7.14)\n",
            "Downloading stable_baselines3-2.2.1-py3-none-any.whl (181 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.7/181.7 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading Shimmy-1.3.0-py3-none-any.whl (37 kB)\n",
            "Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m120.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ale_py-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=autorom_accept_rom_license-0.6.1-py3-none-any.whl size=446709 sha256=3993a4b9c3205d2a70e13bcd73845eef70f1548dc5472681186433a13e3be433\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/fc/c6/8aa657c0d2089982f2dabd110efc68c61eb49831fdb7397351\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: numpy, AutoROM.accept-rom-license, autorom, ale-py, shimmy, stable-baselines3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: ale-py\n",
            "    Found existing installation: ale-py 0.11.2\n",
            "    Uninstalling ale-py-0.11.2:\n",
            "      Successfully uninstalled ale-py-0.11.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires gym<=0.25.2, which is not installed.\n",
            "citylearn 2.3.0 requires numpy<2.0.0, but you have numpy 2.2.6 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires ale-py>=0.10.1, but you have ale-py 0.8.1 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "yfinance 0.2.65 requires beautifulsoup4>=4.11.1, but you have beautifulsoup4 4.8.0 which is incompatible.\n",
            "cuml-cu12 25.6.0 requires scikit-learn>=1.5, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "libpysal 4.13.0 requires beautifulsoup4>=4.10, but you have beautifulsoup4 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.8.1 autorom-0.6.1 numpy-2.2.6 shimmy-1.3.0 stable-baselines3-2.2.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "77210816b84a4cd89776d1731bc3add9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.2.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_scatter-2.1.2%2Bpt20cu118-cp311-cp311-linux_x86_64.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt20cu118\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_sparse-0.6.18%2Bpt20cu118-cp311-cp311-linux_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.16.0)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (2.2.6)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt20cu118\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.12.14)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.2.6)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.7.14)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.14.1)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n",
            "Collecting numpy==1.24.4\n",
            "  Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting scipy==1.10.1\n",
            "  Downloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m119.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.1/34.1 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.6\n",
            "    Uninstalling numpy-2.2.6:\n",
            "      Successfully uninstalled numpy-2.2.6\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.0\n",
            "    Uninstalling scipy-1.16.0:\n",
            "      Successfully uninstalled scipy-1.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires gym<=0.25.2, which is not installed.\n",
            "scikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.10.1 which is incompatible.\n",
            "cvxpy 1.6.7 requires scipy>=1.11.0, but you have scipy 1.10.1 which is incompatible.\n",
            "blosc2 3.6.1 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.10.1 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires scipy>=1.11, but you have scipy 1.10.1 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires ale-py>=0.10.1, but you have ale-py 0.8.1 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "jaxlib 0.5.1 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\n",
            "pymc 5.25.1 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.4 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "yfinance 0.2.65 requires beautifulsoup4>=4.11.1, but you have beautifulsoup4 4.8.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.4 which is incompatible.\n",
            "arviz 0.22.0 requires numpy>=1.26.0, but you have numpy 1.24.4 which is incompatible.\n",
            "arviz 0.22.0 requires scipy>=1.11.0, but you have scipy 1.10.1 which is incompatible.\n",
            "cuml-cu12 25.6.0 requires scikit-learn>=1.5, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.4 which is incompatible.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.4 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "jax 0.5.2 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\n",
            "libpysal 4.13.0 requires beautifulsoup4>=4.10, but you have beautifulsoup4 4.8.0 which is incompatible.\n",
            "xarray 2025.7.1 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.4 scipy-1.10.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "08cb09c27df1437fb9b7445a63f95162"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboard==2.12.3\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.12.3) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.12.3) (1.74.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.12.3) (2.38.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard==2.12.3)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.12.3) (3.8.2)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.12.3) (1.24.4)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.12.3) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.12.3) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.12.3) (75.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.12.3) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.12.3) (3.1.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.12.3) (0.45.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.12.3) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.12.3) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.12.3) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard==2.12.3) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard==2.12.3) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard==2.12.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard==2.12.3) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard==2.12.3) (2025.7.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard==2.12.3) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.12.3) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard==2.12.3) (3.3.1)\n",
            "Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: google-auth-oauthlib, tensorboard\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.2\n",
            "    Uninstalling google-auth-oauthlib-1.2.2:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-oauthlib-1.0.0 tensorboard-2.12.3\n",
            "Collecting tensorflow==2.12.0\n",
            "  Downloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (25.2.10)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12.0)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.74.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.14.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.5.2)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (18.1.1)\n",
            "Collecting numpy<1.24,>=1.22 (from tensorflow==2.12.0)\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (25.0)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.12.0)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.17.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.3)\n",
            "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.14.1)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.12.0)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.45.1)\n",
            "Requirement already satisfied: jaxlib<=0.5.2,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.5.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.1)\n",
            "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib<=0.7.0,>=0.7.0 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.7.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting ml_dtypes>=0.5.0 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading ml_dtypes-0.5.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.6.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib<=0.6.2,>=0.6.2 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.6.2-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.6.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib<=0.6.1,>=0.6.1 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.6.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.6.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.6.0,>=0.6.0 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.6.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.5.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.5.3,>=0.5.3 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.5.3-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.5.1-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.5.0,>=0.5.0 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.5.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (978 bytes)\n",
            "INFO: pip is still looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.38-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.38,>=0.4.38 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.38-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.37-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.37,>=0.4.36 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.36-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.36-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.4.35-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.35,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.35-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.34-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.34,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.34-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.33-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.33,>=0.4.33 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.33-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.31-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.31,>=0.4.30 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.31-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.30-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.30,>=0.4.27 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.30-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2025.7.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.3.1)\n",
            "Downloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (586.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.0/586.0 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading jax-0.4.30-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m116.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.4.30-cp311-cp311-manylinux2014_x86_64.whl (79.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, protobuf, numpy, keras, gast, jaxlib, jax, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.4\n",
            "    Uninstalling numpy-1.24.4:\n",
            "      Successfully uninstalled numpy-1.24.4\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.5.1\n",
            "    Uninstalling jaxlib-0.5.1:\n",
            "      Successfully uninstalled jaxlib-0.5.1\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.5.2\n",
            "    Uninstalling jax-0.5.2:\n",
            "      Successfully uninstalled jax-0.5.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires gym<=0.25.2, which is not installed.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.10.1 which is incompatible.\n",
            "cvxpy 1.6.7 requires scipy>=1.11.0, but you have scipy 1.10.1 which is incompatible.\n",
            "blosc2 3.6.1 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.0 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.10.1 which is incompatible.\n",
            "flax 0.10.6 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires scipy>=1.11, but you have scipy 1.10.1 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires ale-py>=0.10.1, but you have ale-py 0.8.1 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "pymc 5.25.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "geopandas 1.1.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "yfinance 0.2.65 requires beautifulsoup4>=4.11.1, but you have beautifulsoup4 4.8.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "arviz 0.22.0 requires numpy>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "arviz 0.22.0 requires scipy>=1.11.0, but you have scipy 1.10.1 which is incompatible.\n",
            "cuml-cu12 25.6.0 requires scikit-learn>=1.5, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "bigframes 2.12.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "orbax-checkpoint 0.11.19 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "db-dtypes 1.4.3 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.90 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "libpysal 4.13.0 requires beautifulsoup4>=4.10, but you have beautifulsoup4 4.8.0 which is incompatible.\n",
            "xarray 2025.7.1 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 jax-0.4.30 jaxlib-0.4.30 keras-2.12.0 numpy-1.23.5 protobuf-4.25.8 tensorflow-2.12.0 tensorflow-estimator-2.12.0 wrapt-1.14.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy"
                ]
              },
              "id": "4ea52f966cc34f1e97fddc29c5df6efe"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install citylearn==2.3.0\n",
        "!pip uninstall -y gym\n",
        "!pip install gymnasium==0.29.1\n",
        "!pip install stable-baselines3[extra]==2.2.1\n",
        "\n",
        "# Torch + CUDA 11.8\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# PyTorch Geometric\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
        "!pip install torch-geometric\n",
        "\n",
        "# Fix NumPy / SciPy / TensorBoard / TensorFlow\n",
        "!pip install numpy==1.24.4 scipy==1.10.1\n",
        "!pip install tensorboard==2.12.3\n",
        "!pip install tensorflow==2.12.0\n",
        "\n",
        "# Restart runtime\n",
        "import os\n",
        "os.kill(os.getpid(), 9)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Средина: CityLearn\n",
        "CityLearn е симулациска околина за паметни згради. Секој агент одлучува колку енергија да складира или искористи од батеријата со цел да се минимизира потрошувачката и да се балансира мрежата.\n"
      ],
      "metadata": {
        "id": "6ZZ1Shd665op"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PPO агент со CustomReward function**"
      ],
      "metadata": {
        "id": "XqRcVpGicOEn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Custom Reward Function 1: Енергетска ефикасност и економија\n",
        "\n",
        "Оваа функција има за цел да го научи агентот да управува со енергијата на паметен начин:  \n",
        "- Намалување на потрошувачката од мрежата (особено кога струјата е скапа)  \n",
        "- Поголема искористеност на соларната енергија  \n",
        "- Стратегиско користење на батеријата според цените  \n",
        "- Казнување на неефикасни состојби (празна/преполна батерија, лошо темпирање)\n",
        "\n",
        "Секој аспект е дизајниран да го насочи агентот кон одржливо и оптимално однесување.\n"
      ],
      "metadata": {
        "id": "qyFVcFueCYA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from citylearn.reward_function import RewardFunction\n",
        "\n",
        "class CustomReward(RewardFunction):\n",
        "    def __init__(self, env_metadata):\n",
        "        super().__init__(env_metadata)\n",
        "\n",
        "    def calculate(self, observations):\n",
        "        rewards_per_building = []\n",
        "        for o in observations:\n",
        "            net_electricity_consumption = o.get('net_electricity_consumption', 0.0)\n",
        "            solar_generation = o.get('solar_generation', 0.0)\n",
        "            battery_soc = o.get('electrical_storage_soc', 0.5)\n",
        "            electricity_price = o.get('electricity_pricing', 0.0)\n",
        "\n",
        "            # =======================================================\n",
        "            # 1. Минимизирање на нето-потрошувачка (пресметана со цена)\n",
        "            # =======================================================\n",
        "            # Награда е негативна вредност на потрошената енергија.\n",
        "            # Ова го поттикнува да купува помалку струја, особено кога е скапа.\n",
        "            # Многу позитивно ако продаваш струја на мрежата (net_electricity_consumption < 0)\n",
        "            reward = -1.0 * net_electricity_consumption * electricity_price\n",
        "\n",
        "            # =======================================================\n",
        "            # 2. Искористување на соларна енергија\n",
        "            # =======================================================\n",
        "            # Позитивна награда за генерирање соларна енергија.\n",
        "            # Можеби не директно *solar_generation*, туку колку таа помогнала\n",
        "            # да се намали купувањето или да се полни батеријата.\n",
        "            # Засега, едноставна позитивна вредност.\n",
        "            reward += 0.2 * solar_generation\n",
        "\n",
        "            # =======================================================\n",
        "            # 3. Управување со батеријата (со оглед на цената)\n",
        "            # =======================================================\n",
        "            # а) Казна за празна батерија кога потрошувачката е висока\n",
        "            if net_electricity_consumption > 0 and battery_soc < 0.1:\n",
        "                reward -= 0.5\n",
        "\n",
        "            # б) Казна за преполна батерија кога има соларна генерација И ниска потрошувачка\n",
        "            # Ова го охрабрува да ја празни за да направи место за соларна.\n",
        "            if battery_soc > 0.9 and net_electricity_consumption < 0.1 and solar_generation > 0.1:\n",
        "                reward -= 0.3\n",
        "\n",
        "            #  в) Награда за полнење кога цената е ниска (купувај евтино)\n",
        "            # Ова претпоставува дека ниска цена е < 0.1 (пример).\n",
        "            # Прилагоди го прагот според реалните цени во твојата симулација.\n",
        "            # Ако агентот одлучил да купи струја (акција > 0, т.е. полни батерија)\n",
        "            # и цената е ниска.\n",
        "            if electricity_price < 0.1 and o.get('charging_rate', 0.0) > 0: # Додавање на 'charging_rate' ако е достапно\n",
        "                reward += 0.1 # Мал поттик за евтино полнење\n",
        "\n",
        "            #  г) Награда за празнење кога цената е висока (продавај или користи скапо складирана енергија)\n",
        "            # Ако агентот одлучил да празни (акција < 0, т.е. празни батерија)\n",
        "            # и цената е висока.\n",
        "            if electricity_price > 0.5 and o.get('discharging_rate', 0.0) > 0:\n",
        "                reward += 0.1\n",
        "\n",
        "            # д) Мала казна за отстапување од средина (сеуште корисно)\n",
        "            reward -= 0.05 * abs(battery_soc - 0.5)\n",
        "\n",
        "            rewards_per_building.append(np.clip(reward, -20.0, 20.0))\n",
        "\n",
        "        return rewards_per_building"
      ],
      "metadata": {
        "id": "8uRfLh2DkAnC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Тренирање на PPO + LSTM + GNN агент со динамичен граф\n",
        "\n",
        "Овој дел го иницијализира и тренира агентот користејќи:\n",
        "- **PPO алгоритам** со LSTM меморија за секвенцијално учење\n",
        "- **GNN (Graph Neural Network)** за искористување на информации од други слични згради\n",
        "- **Dynamic Graph**: графот се ажурира пред секој чекор за да се одразат најновите енергетски карактеристики\n",
        "- **Custom Reward Function** дефинирана претходно за да се поттикне енергетска ефикасност\n",
        "\n",
        "Се тренира агент само за една зграда (централизиран PPO) со временски контекст (12 чекори).  \n",
        "Се користи и `EvalCallback` за редовна евалуација и зачувување на најдобриот модел.\n"
      ],
      "metadata": {
        "id": "SsgSlMSuYWfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch_geometric.nn import GATv2Conv\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from gymnasium import Env, spaces\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
        "from stable_baselines3.common.policies import ActorCriticPolicy\n",
        "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback\n",
        "from citylearn.citylearn import CityLearnEnv\n",
        "from citylearn.reward_function import RewardFunction\n",
        "\n",
        "\n",
        "# ========== Dynamic Graph Builder ==========\n",
        "def build_dynamic_graph(env, k=2):\n",
        "    n = len(env.buildings)\n",
        "    feats = []\n",
        "    for b in env.buildings:\n",
        "        feats.append([\n",
        "            b.net_electricity_consumption[-1],\n",
        "            b.solar_generation[-1],\n",
        "            b.electrical_storage.soc[-1]\n",
        "        ])\n",
        "    features = np.array(feats)\n",
        "    features = StandardScaler().fit_transform(features)\n",
        "    dists = euclidean_distances(features)\n",
        "\n",
        "    edge_index, edge_attr = [], []\n",
        "    for i in range(n):\n",
        "        nearest = np.argsort(dists[i])[1:k+1]\n",
        "        for j in nearest:\n",
        "            weight = 1.0 / (dists[i][j] + 1e-6)\n",
        "            edge_index += [[i, j], [j, i]]\n",
        "            edge_attr += [[weight], [weight]]\n",
        "\n",
        "    return (\n",
        "        torch.tensor(features, dtype=torch.float32),\n",
        "        torch.tensor(edge_index).T.long(),\n",
        "        torch.tensor(edge_attr).float()\n",
        "    )\n",
        "\n",
        "# ========== Env Wrapper ==========\n",
        "class CityLearnSingleBuildingWrapper(Env):\n",
        "    def __init__(self, env, building_id=0, seq_len=12):\n",
        "        super().__init__()\n",
        "        self.env = env\n",
        "        self.building_id = building_id\n",
        "        self.seq_len = seq_len\n",
        "        self.n_buildings = len(env.action_space)\n",
        "        self.obs_dim = env.observation_space[building_id].shape[0]\n",
        "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(seq_len * self.obs_dim,), dtype=np.float32)\n",
        "        self.buffer = []\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        obs, _ = self.env.reset(**kwargs)\n",
        "        self.buffer = []\n",
        "        o = obs[self.building_id]\n",
        "        for _ in range(self.seq_len):\n",
        "            self.buffer.append(o)\n",
        "        return np.concatenate(self.buffer), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        actions = [[0.0] * self.env.action_space[0].shape[0] for _ in range(self.n_buildings)]\n",
        "        actions[self.building_id] = [float(action[0])]\n",
        "        obs, reward, done, trunc, info = self.env.step(actions)\n",
        "        o = obs[self.building_id]\n",
        "        self.buffer.pop(0)\n",
        "        self.buffer.append(o)\n",
        "        return np.concatenate(self.buffer), reward[self.building_id], done, trunc, info\n",
        "\n",
        "# ========== Feature Extractor ==========\n",
        "class GNN_LSTM_FeatureExtractor(BaseFeaturesExtractor):\n",
        "    def __init__(self, observation_space, env, hidden_size=64, lstm_layers=1):\n",
        "        super().__init__(observation_space, features_dim=hidden_size)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.obs_dim = observation_space.shape[0] // 12\n",
        "        self.lstm = nn.LSTM(self.obs_dim, hidden_size, lstm_layers, batch_first=True)\n",
        "        self.hidden = None\n",
        "        self.env = env\n",
        "        self.building_id = env.building_id if hasattr(env, 'building_id') else 0\n",
        "        self.graph_x = torch.zeros((len(env.buildings), 3), dtype=torch.float32)\n",
        "        self.edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "        self.edge_attr = torch.empty((0, 1), dtype=torch.float32)\n",
        "        self.gnn1 = GATv2Conv(3, hidden_size, edge_dim=1)\n",
        "        self.gnn2 = GATv2Conv(hidden_size, hidden_size, edge_dim=1)\n",
        "\n",
        "    def update_graph(self):\n",
        "        graph_x, edge_index, edge_attr = build_dynamic_graph(self.env)\n",
        "        self.graph_x = graph_x\n",
        "        self.edge_index = edge_index\n",
        "        self.edge_attr = edge_attr\n",
        "\n",
        "    def forward(self, obs):\n",
        "        batch_size = obs.shape[0]\n",
        "        x = obs.view(batch_size, 12, self.obs_dim).float()\n",
        "        if self.hidden is None or self.hidden[0].shape[1] != batch_size:\n",
        "            h0 = torch.zeros(self.lstm.num_layers, batch_size, self.hidden_size).to(x.device)\n",
        "            c0 = torch.zeros(self.lstm.num_layers, batch_size, self.hidden_size).to(x.device)\n",
        "            self.hidden = (h0, c0)\n",
        "        lstm_out, self.hidden = self.lstm(x, self.hidden)\n",
        "        self.hidden = (self.hidden[0].detach(), self.hidden[1].detach())\n",
        "        lstm_feature = lstm_out[:, -1, :]\n",
        "\n",
        "        gx = self.graph_x.to(x.device)\n",
        "        ei = self.edge_index.to(x.device)\n",
        "        ea = self.edge_attr.to(x.device)\n",
        "        gx = torch.relu(self.gnn1(gx, ei, ea))\n",
        "        gx = torch.relu(self.gnn2(gx, ei, ea))\n",
        "\n",
        "\n",
        "        gnn_feature = gx[self.building_id].unsqueeze(0).expand(batch_size, -1)\n",
        "\n",
        "        return lstm_feature + gnn_feature\n",
        "\n",
        "# ========== Policy ==========\n",
        "class CustomGNNLSTMPolicy(ActorCriticPolicy):\n",
        "    def __init__(self, observation_space, action_space, lr_schedule, env, **kwargs):\n",
        "        super().__init__(\n",
        "            observation_space,\n",
        "            action_space,\n",
        "            lr_schedule,\n",
        "            features_extractor_class=GNN_LSTM_FeatureExtractor,\n",
        "            features_extractor_kwargs={\"env\": env},\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "# ========== Callback ==========\n",
        "class DynamicGraphCallback(BaseCallback):\n",
        "    def __init__(self, verbose=0):\n",
        "        super().__init__(verbose)\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        self.model.policy.features_extractor.update_graph()\n",
        "        return True\n",
        "\n",
        "# ========== Main ==========\n",
        "if __name__ == '__main__':\n",
        "    env = CityLearnEnv(\n",
        "        schema='citylearn_challenge_2022_phase_1',\n",
        "        reward_function=CustomReward,\n",
        "        central_agent=False\n",
        "    )\n",
        "\n",
        "    single_building_env = CityLearnSingleBuildingWrapper(env, building_id=0, seq_len=12)\n",
        "    vec_env = DummyVecEnv([lambda: single_building_env])\n",
        "\n",
        "    model = PPO(\n",
        "        CustomGNNLSTMPolicy,\n",
        "        vec_env,\n",
        "        normalize_advantage=True,\n",
        "        verbose=1,\n",
        "        n_steps=1024,\n",
        "        batch_size=64,\n",
        "        learning_rate=3e-4,\n",
        "        gamma=0.99,\n",
        "        gae_lambda=0.95,\n",
        "        ent_coef=0.01,\n",
        "        vf_coef=0.4,\n",
        "        max_grad_norm=0.5,\n",
        "        policy_kwargs={\"env\": env}\n",
        "    )\n",
        "\n",
        "    model.policy.features_extractor.update_graph()\n",
        "\n",
        "    eval_env = DummyVecEnv([\n",
        "        lambda: Monitor(CityLearnSingleBuildingWrapper(env, building_id=0, seq_len=12))\n",
        "    ])\n",
        "    eval_callback = EvalCallback(\n",
        "        eval_env,\n",
        "        best_model_save_path=\"./logs/best_model\",\n",
        "        log_path=\"./logs/eval\",\n",
        "        eval_freq=1024,\n",
        "        deterministic=True,\n",
        "        render=False\n",
        "    )\n",
        "\n",
        "    model.learn(total_timesteps=500_000, callback=[DynamicGraphCallback(), eval_callback])\n",
        "    model.save(\"ppo_gnn_lstm_dynamic_graph\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iKxqIlAY_7ei",
        "outputId": "522efbe9-3651-4127-a126-c06441612a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Eval num_timesteps=1024, episode_reward=-2936.11 +/- 0.00\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 8.76e+03  |\n",
            "|    mean_reward     | -2.94e+03 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1024      |\n",
            "----------------------------------\n",
            "New best mean reward!\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1    |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 696  |\n",
            "|    total_timesteps | 1024 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=2048, episode_reward=-993.82 +/- 0.20\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -994         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 2048         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021014106 |\n",
            "|    clip_fraction        | 0.00859      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0.0934       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.14         |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00269     |\n",
            "|    std                  | 0.993        |\n",
            "|    value_loss           | 5.41         |\n",
            "------------------------------------------\n",
            "New best mean reward!\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1    |\n",
            "|    iterations      | 2    |\n",
            "|    time_elapsed    | 1406 |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=3072, episode_reward=-734.26 +/- 0.00\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 8.76e+03    |\n",
            "|    mean_reward          | -734        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 3072        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005945214 |\n",
            "|    clip_fraction        | 0.0479      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | 0.479       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.46        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00771    |\n",
            "|    std                  | 0.991       |\n",
            "|    value_loss           | 5.14        |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1    |\n",
            "|    iterations      | 3    |\n",
            "|    time_elapsed    | 2107 |\n",
            "|    total_timesteps | 3072 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=4096, episode_reward=-1019.18 +/- 0.00\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 8.76e+03    |\n",
            "|    mean_reward          | -1.02e+03   |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006901043 |\n",
            "|    clip_fraction        | 0.0694      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | 0.496       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.56        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00727    |\n",
            "|    std                  | 0.989       |\n",
            "|    value_loss           | 5.02        |\n",
            "-----------------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1    |\n",
            "|    iterations      | 4    |\n",
            "|    time_elapsed    | 2802 |\n",
            "|    total_timesteps | 4096 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=5120, episode_reward=-833.43 +/- 0.00\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 8.76e+03   |\n",
            "|    mean_reward          | -833       |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 5120       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00323179 |\n",
            "|    clip_fraction        | 0.0205     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.41      |\n",
            "|    explained_variance   | 0.566      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.16       |\n",
            "|    n_updates            | 40         |\n",
            "|    policy_gradient_loss | -0.00428   |\n",
            "|    std                  | 0.99       |\n",
            "|    value_loss           | 3.35       |\n",
            "----------------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1    |\n",
            "|    iterations      | 5    |\n",
            "|    time_elapsed    | 3506 |\n",
            "|    total_timesteps | 5120 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=6144, episode_reward=-859.22 +/- 0.12\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -859         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037699568 |\n",
            "|    clip_fraction        | 0.0262       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.627        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.24         |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.00609     |\n",
            "|    std                  | 0.993        |\n",
            "|    value_loss           | 2.53         |\n",
            "------------------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1    |\n",
            "|    iterations      | 6    |\n",
            "|    time_elapsed    | 4206 |\n",
            "|    total_timesteps | 6144 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=7168, episode_reward=-807.13 +/- 0.12\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -807         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 7168         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043685017 |\n",
            "|    clip_fraction        | 0.0268       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.629        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.03         |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.00564     |\n",
            "|    std                  | 0.987        |\n",
            "|    value_loss           | 2.69         |\n",
            "------------------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1    |\n",
            "|    iterations      | 7    |\n",
            "|    time_elapsed    | 4916 |\n",
            "|    total_timesteps | 7168 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=8192, episode_reward=-661.72 +/- 0.00\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -662         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051530483 |\n",
            "|    clip_fraction        | 0.031        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.637        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.871        |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.00658     |\n",
            "|    std                  | 0.993        |\n",
            "|    value_loss           | 2.69         |\n",
            "------------------------------------------\n",
            "New best mean reward!\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1    |\n",
            "|    iterations      | 8    |\n",
            "|    time_elapsed    | 5624 |\n",
            "|    total_timesteps | 8192 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=9216, episode_reward=-646.42 +/- 0.00\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -646         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 9216         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054581454 |\n",
            "|    clip_fraction        | 0.0307       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.624        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.74         |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -0.00379     |\n",
            "|    std                  | 0.988        |\n",
            "|    value_loss           | 3.28         |\n",
            "------------------------------------------\n",
            "New best mean reward!\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1    |\n",
            "|    iterations      | 9    |\n",
            "|    time_elapsed    | 6328 |\n",
            "|    total_timesteps | 9216 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=10240, episode_reward=-680.01 +/- 0.00\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 8.76e+03    |\n",
            "|    mean_reward          | -680        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007267614 |\n",
            "|    clip_fraction        | 0.0648      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.4        |\n",
            "|    explained_variance   | 0.682       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.37        |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.011      |\n",
            "|    std                  | 0.979       |\n",
            "|    value_loss           | 2.64        |\n",
            "-----------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 1     |\n",
            "|    iterations      | 10    |\n",
            "|    time_elapsed    | 7045  |\n",
            "|    total_timesteps | 10240 |\n",
            "------------------------------\n",
            "Eval num_timesteps=11264, episode_reward=-734.46 +/- 0.06\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 8.76e+03    |\n",
            "|    mean_reward          | -734        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 11264       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006147336 |\n",
            "|    clip_fraction        | 0.0376      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.4        |\n",
            "|    explained_variance   | 0.693       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.51        |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.00452    |\n",
            "|    std                  | 0.987       |\n",
            "|    value_loss           | 2.65        |\n",
            "-----------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 1     |\n",
            "|    iterations      | 11    |\n",
            "|    time_elapsed    | 7751  |\n",
            "|    total_timesteps | 11264 |\n",
            "------------------------------\n",
            "Eval num_timesteps=12288, episode_reward=-781.62 +/- 0.02\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -782         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 12288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0062139444 |\n",
            "|    clip_fraction        | 0.0517       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.708        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.941        |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.00649     |\n",
            "|    std                  | 0.988        |\n",
            "|    value_loss           | 2.67         |\n",
            "------------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 1     |\n",
            "|    iterations      | 12    |\n",
            "|    time_elapsed    | 8460  |\n",
            "|    total_timesteps | 12288 |\n",
            "------------------------------\n",
            "Eval num_timesteps=13312, episode_reward=-870.08 +/- 0.02\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 8.76e+03    |\n",
            "|    mean_reward          | -870        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 13312       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007962313 |\n",
            "|    clip_fraction        | 0.104       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | 0.709       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.576       |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.00477    |\n",
            "|    std                  | 0.992       |\n",
            "|    value_loss           | 2.58        |\n",
            "-----------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 1     |\n",
            "|    iterations      | 13    |\n",
            "|    time_elapsed    | 9175  |\n",
            "|    total_timesteps | 13312 |\n",
            "------------------------------\n",
            "Eval num_timesteps=14336, episode_reward=-872.69 +/- 0.03\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -873         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051853782 |\n",
            "|    clip_fraction        | 0.0365       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.72         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.11         |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | -0.00595     |\n",
            "|    std                  | 0.994        |\n",
            "|    value_loss           | 2.53         |\n",
            "------------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 1     |\n",
            "|    iterations      | 14    |\n",
            "|    time_elapsed    | 9888  |\n",
            "|    total_timesteps | 14336 |\n",
            "------------------------------\n",
            "Eval num_timesteps=15360, episode_reward=-838.12 +/- 0.00\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -838         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 15360        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0077824127 |\n",
            "|    clip_fraction        | 0.0482       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.746        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.844        |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -0.00334     |\n",
            "|    std                  | 0.993        |\n",
            "|    value_loss           | 2.51         |\n",
            "------------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 1     |\n",
            "|    iterations      | 15    |\n",
            "|    time_elapsed    | 10615 |\n",
            "|    total_timesteps | 15360 |\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-5-3089795798.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    213\u001b[0m     )\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500_000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDynamicGraphCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ppo_gnn_lstm_dynamic_graph\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     ) -> SelfPPO:\n\u001b[0;32m--> 315\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    316\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# Give access to local variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_locals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/callbacks.py\u001b[0m in \u001b[0;36mon_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/callbacks.py\u001b[0m in \u001b[0;36m_on_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;31m# Return False (stop training) if at least one callback returns False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/callbacks.py\u001b[0m in \u001b[0;36mon_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/callbacks.py\u001b[0m in \u001b[0;36m_on_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_success_buffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m             episode_rewards, episode_lengths = evaluate_policy(\n\u001b[0m\u001b[1;32m    461\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_env\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py\u001b[0m in \u001b[0;36mevaluate_policy\u001b[0;34m(model, env, n_eval_episodes, deterministic, render, callback, reward_threshold, return_episode_rewards, warn)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         )\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mnew_observations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mcurrent_rewards\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mcurrent_lengths\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \"\"\"\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Avoid circular imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/monitor.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tried to step environment that needs reset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mterminated\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-5-3089795798.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_buildings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilding_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilding_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/citylearn/citylearn.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbuilding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuilding_actions\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuildings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m             \u001b[0mbuilding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbuilding_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/citylearn/building.py\u001b[0m in \u001b[0;36mapply_actions\u001b[0;34m(self, cooling_or_heating_device_action, cooling_device_action, heating_device_action, cooling_storage_action, heating_storage_action, dhw_storage_action, electrical_storage_action, electric_vehicle_storage_actions)\u001b[0m\n\u001b[1;32m   1142\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1144\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_cooling_demand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/citylearn/building.py\u001b[0m in \u001b[0;36mupdate_variables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2081\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melectric_vehicle_chargers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2083\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melectric_vehicle_chargers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2084\u001b[0m                 \u001b[0mbuilding_chargers_total_electricity_consumption\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2085\u001b[0m                     \u001b[0mbuilding_chargers_total_electricity_consumption\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melectricity_consumption\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_step\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/citylearn/building.py\u001b[0m in \u001b[0;36melectric_vehicle_chargers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0melectric_vehicle_chargers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCharger\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;34m\"\"\"Electric Vehicle Chargers associated with the building for charging connected eletric vehicles.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "\n",
        "eval_data_path = '/content/logs/eval/evaluations_CustomReward.npz'\n",
        "\n",
        "try:\n",
        "\n",
        "    data = np.load(eval_data_path)\n",
        "\n",
        "    timesteps = data['timesteps']\n",
        "    results = data['results']\n",
        "\n",
        "    mean_rewards = np.mean(results, axis=1)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(timesteps, mean_rewards, label='Mean Evaluation Reward')\n",
        "    plt.title('Agent Performance During Training (Evaluation Callback)')\n",
        "    plt.xlabel('Timesteps')\n",
        "    plt.ylabel('Mean Reward')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"✅ Loaded {len(timesteps)} evaluation points.\")\n",
        "    print(f\"First 5 timesteps: {timesteps[:5]}\")\n",
        "    print(f\"First 5 mean rewards: {mean_rewards[:5]}\")\n",
        "    print(f\"Shape of 'results' array: {results.shape}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"❌ Error: evaluations.npz not found at {eval_data_path}\")\n",
        "    print(\"Please ensure the path is correct and the EvalCallback was configured to save this file.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ An unexpected error occurred: {e}\")\n",
        "    print(f\"Keys available in npz: {list(data.keys())}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "Q31iG3uPa4ky",
        "outputId": "3f2dec37-2265-4525-d15c-0b7076255abc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded 15 evaluation points.\n",
            "First 5 timesteps: [1024 2048 3072 4096 5120]\n",
            "First 5 mean rewards: [-2936.1099152  -993.8173378  -734.2564848 -1019.1838616  -833.432332 ]\n",
            "Shape of 'results' array: (15, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📈 Графикон: Просечна награда за време на тренирање\n",
        "\n",
        "Овој графикон ја прикажува промената на **просечната евалуациска награда** на агентот во текот на тренирањето, мерена на секои 1024 чекори. Агентот покажува брзо подобрување во првите епизоди, достигнувајќи стабилно ниво на награда по околу 8000 чекори. Ова укажува дека политиката успешно научила ефективна стратегија во рана фаза од тренингот и продолжува со доследна изведба.\n"
      ],
      "metadata": {
        "id": "z7mHXbLhZUfT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🧪 Евалуација на агентот на други згради\n",
        "\n",
        "Откако PPO агентот беше трениран исклучиво на зграда 0, се изврши евалуација на останатите згради (2, 3, 4 и 5) од истата околина.  \n",
        "Целта на оваа анализа е да се провери колку научената политика може да се пренесе и на други згради со различна динамика и потрошувачка на енергија.\n"
      ],
      "metadata": {
        "id": "3KHSGyWJaYrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "env = CityLearnEnv(\n",
        "    schema='citylearn_challenge_2022_phase_1',\n",
        "    reward_function=CustomReward,\n",
        "    central_agent=False\n",
        ")\n",
        "\n",
        "test_building_id = 2\n",
        "eval_env = CityLearnSingleBuildingWrapper(env, building_id=test_building_id, seq_len=12)\n",
        "\n",
        "model = PPO.load(\"best_model.zip\")\n",
        "\n",
        "obs, _ = eval_env.reset()\n",
        "done = False\n",
        "total_reward = 0\n",
        "\n",
        "while not done:\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, _, _ = eval_env.step(action)\n",
        "    total_reward += reward\n",
        "\n",
        "print(f\"📊 Total reward on unseen building {test_building_id}: {total_reward:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOcFFXyoTKUU",
        "outputId": "e17a778c-83bd-43f0-c12f-c0a4c6059585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Total reward on unseen building 2: -138.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "env = CityLearnEnv(\n",
        "    schema='citylearn_challenge_2022_phase_1',\n",
        "    reward_function=CustomReward,\n",
        "    central_agent=False\n",
        ")\n",
        "\n",
        "test_building_id = 4\n",
        "eval_env = CityLearnSingleBuildingWrapper(env, building_id=test_building_id, seq_len=12)\n",
        "\n",
        "model = PPO.load(\"best_model.zip\")\n",
        "\n",
        "obs, _ = eval_env.reset()\n",
        "done = False\n",
        "total_reward = 0\n",
        "\n",
        "while not done:\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, _, _ = eval_env.step(action)\n",
        "    total_reward += reward\n",
        "\n",
        "print(f\"📊 Total reward on unseen building {test_building_id}: {total_reward:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5Q9J3H3te13",
        "outputId": "6952ceaa-2c5d-4a33-ed9a-3b40a1aa3123"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Total reward on unseen building 4: -579.69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "env = CityLearnEnv(\n",
        "    schema='citylearn_challenge_2022_phase_1',\n",
        "    reward_function=CustomReward,\n",
        "    central_agent=False\n",
        ")\n",
        "\n",
        "test_building_id = 1\n",
        "eval_env = CityLearnSingleBuildingWrapper(env, building_id=test_building_id, seq_len=12)\n",
        "\n",
        "model = PPO.load(\"best_model.zip\")\n",
        "\n",
        "obs, _ = eval_env.reset()\n",
        "done = False\n",
        "total_reward = 0\n",
        "\n",
        "while not done:\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, _, _ = eval_env.step(action)\n",
        "    total_reward += reward\n",
        "\n",
        "print(f\"📊 Total reward on unseen building {test_building_id}: {total_reward:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiP_dtNHvera",
        "outputId": "30973938-a74d-4b2a-9788-34f3e2aa24c0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Total reward on unseen building 1: -903.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "env = CityLearnEnv(\n",
        "    schema='citylearn_challenge_2022_phase_1',\n",
        "    reward_function=CustomReward,\n",
        "    central_agent=False\n",
        ")\n",
        "\n",
        "test_building_id = 3\n",
        "eval_env = CityLearnSingleBuildingWrapper(env, building_id=test_building_id, seq_len=12)\n",
        "\n",
        "model = PPO.load(\"best_model.zip\")\n",
        "\n",
        "obs, _ = eval_env.reset()\n",
        "done = False\n",
        "total_reward = 0\n",
        "\n",
        "while not done:\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, _, _ = eval_env.step(action)\n",
        "    total_reward += reward\n",
        "\n",
        "print(f\"📊 Total reward on unseen building {test_building_id}: {total_reward:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMBz_JAQvhn9",
        "outputId": "b020b19b-2090-4c3b-eae2-ba477035c933"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Total reward on unseen building 3: -625.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Зграда | Вкупна Награда |\n",
        "| ------ | -------------- |\n",
        "| 2      | -138.24        |\n",
        "| 3      | -625.10        |\n",
        "| 4      | -579.69        |\n",
        "| 1      | -903.35        |\n",
        "\n",
        "Иако агентот е трениран само на зграда 0, тој покажува релативно добра генерализација при пренос на политика на зграда 2 (награда: -138.24), што може да значи дека таа зграда има сличен шаблон на потрошувачка. Наспроти тоа, значително полоши перформанси се забележани на зграда 5 (-903.35), што може да укажува на различна динамика која агентот не ја научил при тренинг.\n",
        "\n",
        "Ова покажува дека тренингот на една зграда може да даде ограничени резултати на останатите, и потенцијално сугерира потреба од:\n",
        "- тренинг со централен агент на повеќе згради\n",
        "- дополнителна фина адаптација (fine-tuning)\n",
        "- подобра генерализирачка архитектура и reward функција\n",
        "\n"
      ],
      "metadata": {
        "id": "mndRMV5zafv_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PPO агент со SimpleReward function**"
      ],
      "metadata": {
        "id": "pl23DAGGpNyb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  SimpleReward: Поедноставена наградна функција\n",
        "\n",
        "Оваа наградна функција е дизајнирана со цел да се користи **поедноставен сигнал** за учење, без директна интеграција на електричната цена во пресметките. Таа го поттикнува агентот:\n",
        "\n",
        "- Да **намали потрошувачка на енергија од мрежата**\n",
        "- Да **искористи соларна енергија** кога е достапна\n",
        "- Да **управува со батеријата** без премногу сложени сценарија (на пр., не се користи цена)\n",
        "- Да **одржува баланс** на состојбата на батеријата околу 50%\n",
        "\n",
        "Овој reward е добар за споредба со покомплексната функција бидејќи покажува како влијае богатството на наградниот сигнал врз процесот на учење на агентот.\n"
      ],
      "metadata": {
        "id": "Ue0tnIrzbZQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from citylearn.reward_function import RewardFunction\n",
        "\n",
        "# ========== Custom Reward ==========\n",
        "class SimpleReward(RewardFunction):\n",
        "    def __init__(self, env_metadata):\n",
        "        super().__init__(env_metadata)\n",
        "\n",
        "    def calculate(self, observations):\n",
        "        rewards_per_building = []\n",
        "        for o in observations:\n",
        "            net_electricity_consumption = o.get('net_electricity_consumption', 0.0)\n",
        "            solar_generation = o.get('solar_generation', 0.0)\n",
        "            battery_soc = o.get('electrical_storage_soc', 0.5)\n",
        "\n",
        "            # =======================================================\n",
        "            # 1. Минимизирање на нето-потрошувачка\n",
        "            # =======================================================\n",
        "            # Главната цел е да се минимизира купената електрична енергија.\n",
        "            # Оваа негативна награда го поттикнува агентот да користи помалку\n",
        "            # струја од мрежата или да произведува повеќе од неа.\n",
        "            # Ако агентот продава струја (net_electricity_consumption < 0), наградата станува позитивна.\n",
        "            reward = -1.0 * net_electricity_consumption\n",
        "\n",
        "            # =======================================================\n",
        "            # 2. Искористување на соларна енергија\n",
        "            # =======================================================\n",
        "            # Позитивна награда за генерирање соларна енергија.\n",
        "            # Ова го охрабрува агентот да ги цени и искористи моментите кога\n",
        "            # соларните панели произведуваат енергија.\n",
        "            reward += 0.2 * solar_generation\n",
        "\n",
        "            # =======================================================\n",
        "            # 3. Управување со батеријата\n",
        "            # =======================================================\n",
        "            # а) Казна за празна батерија кога има потреба од енергија\n",
        "            # Ако потрошувачката е позитивна (купуваш струја), а батеријата е речиси празна,\n",
        "            # тоа значи дека агентот не успеал да ја искористи складираната енергија кога му била најпотребна.\n",
        "            if net_electricity_consumption > 0 and battery_soc < 0.1:\n",
        "                reward -= 0.5\n",
        "\n",
        "            # б) Казна за преполна батерија кога има соларна енергија\n",
        "            # Ова го поттикнува агентот да ја празни батеријата (да ја користи или продава струјата)\n",
        "            # за да направи место за новата соларна енергија, која инаку би била изгубена.\n",
        "            if battery_soc > 0.9 and net_electricity_consumption < 0.1 and solar_generation > 0.1:\n",
        "                reward -= 0.3\n",
        "\n",
        "            # в) Награда за полнење кога има доволно простор во батеријата и потрошувачката е висока\n",
        "            # Ова е мал поттик да се искористи батеријата за да се задоволат\n",
        "            # потребите на зградата кога тие се високи.\n",
        "            if net_electricity_consumption > 0.5 and battery_soc > 0.2:\n",
        "                reward += 0.1 * (battery_soc - 0.2)\n",
        "\n",
        "            # г) Мала казна за отстапување од идеална состојба на батеријата\n",
        "            # Ова го насочува агентот да се обиде да ја одржи батеријата околу 50%\n",
        "            # (не премногу полна, ниту премногу празна), што обезбедува флексибилност\n",
        "            # и за полнење и за празнење во иднина.\n",
        "            reward -= 0.05 * abs(battery_soc - 0.5)\n",
        "\n",
        "            rewards_per_building.append(np.clip(reward, -20.0, 20.0))\n",
        "        return rewards_per_building"
      ],
      "metadata": {
        "id": "9JxeDLRRbYBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Тренирање на PPO агентот со GNN + LSTM и поедноставена наградна функција\n",
        "\n",
        "Во овој дел, се тренира PPO агент кој користи комбинација од:\n",
        "\n",
        "- **LSTM**: за обработка на секвенцијални податоци (12-часовна историја на опсервации)\n",
        "- **GNN (Graph Neural Network)**: за искористување на сличноста помеѓу згради преку динамички ажурирана граф структура\n",
        "- **Поедноставена наградна функција (SimpleReward)**: која не го зема предвид цената на струјата, туку се фокусира на нето потрошувачка, соларна генерација и управување со батеријата.\n",
        "\n",
        "Тренирањето се врши на една конкретна зграда (зграда 0), додека графот се ажурира на секој чекор со цел да го рефлектира моменталното сличностно однесување на зградите. Тренирањето се изведува во текот на **500,000 чекори**, а на секои **1024 чекори се врши евалуација**.\n",
        "\n",
        "Моделот се зачувува по завршување на тренирањето, а исто така се чуваат и најдобрите тежини според евалуација.\n"
      ],
      "metadata": {
        "id": "XI-B-l8qeDWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch_geometric.nn import GATv2Conv\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from gymnasium import Env, spaces\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
        "from stable_baselines3.common.policies import ActorCriticPolicy\n",
        "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback\n",
        "from citylearn.citylearn import CityLearnEnv\n",
        "from citylearn.reward_function import RewardFunction\n",
        "\n",
        "# ========== Custom Reward ==========\n",
        "class SimpleReward(RewardFunction):\n",
        "     def __init__(self, env_metadata):\n",
        "         super().__init__(env_metadata)\n",
        "\n",
        "     def calculate(self, observations):\n",
        "         rewards_per_building = []\n",
        "         for o in observations:\n",
        "             net_electricity_consumption = o.get('net_electricity_consumption', 0.0)\n",
        "             solar_generation = o.get('solar_generation', 0.0)\n",
        "             battery_soc = o.get('electrical_storage_soc', 0.5)\n",
        "\n",
        "             reward = -1.0 * net_electricity_consumption\n",
        "             reward += 0.2 * solar_generation\n",
        "\n",
        "             if net_electricity_consumption > 0 and battery_soc < 0.1:\n",
        "                 reward -= 0.5\n",
        "\n",
        "             if battery_soc > 0.9 and net_electricity_consumption < 0.1 and solar_generation > 0.1:\n",
        "                 reward -= 0.3\n",
        "\n",
        "             if net_electricity_consumption > 0.5 and battery_soc > 0.2:\n",
        "                 reward += 0.1 * (battery_soc - 0.2)\n",
        "\n",
        "             reward -= 0.05 * abs(battery_soc - 0.5)\n",
        "\n",
        "             rewards_per_building.append(np.clip(reward, -20.0, 20.0))\n",
        "         return rewards_per_building\n",
        "\n",
        "# ========== Dynamic Graph Builder ==========\n",
        "def build_dynamic_graph(env, k=2):\n",
        "    n = len(env.buildings)\n",
        "    feats = []\n",
        "    for b in env.buildings:\n",
        "        feats.append([\n",
        "            b.net_electricity_consumption[-1],\n",
        "            b.solar_generation[-1],\n",
        "            b.electrical_storage.soc[-1]\n",
        "        ])\n",
        "    features = np.array(feats)\n",
        "    features = StandardScaler().fit_transform(features)\n",
        "    dists = euclidean_distances(features)\n",
        "\n",
        "    edge_index, edge_attr = [], []\n",
        "    for i in range(n):\n",
        "        nearest = np.argsort(dists[i])[1:k+1]\n",
        "        for j in nearest:\n",
        "            weight = 1.0 / (dists[i][j] + 1e-6)\n",
        "            edge_index += [[i, j], [j, i]]\n",
        "            edge_attr += [[weight], [weight]]\n",
        "\n",
        "    return (\n",
        "        torch.tensor(features, dtype=torch.float32),\n",
        "        torch.tensor(edge_index).T.long(),\n",
        "        torch.tensor(edge_attr).float()\n",
        "    )\n",
        "\n",
        "# ========== Env Wrapper ==========\n",
        "class CityLearnSingleBuildingWrapper(Env):\n",
        "    def __init__(self, env, building_id=0, seq_len=12):\n",
        "        super().__init__()\n",
        "        self.env = env\n",
        "        self.building_id = building_id\n",
        "        self.seq_len = seq_len\n",
        "        self.n_buildings = len(env.action_space)\n",
        "        self.obs_dim = env.observation_space[building_id].shape[0]\n",
        "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(seq_len * self.obs_dim,), dtype=np.float32)\n",
        "        self.buffer = []\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        obs, _ = self.env.reset(**kwargs)\n",
        "        self.buffer = []\n",
        "        o = obs[self.building_id]\n",
        "        for _ in range(self.seq_len):\n",
        "            self.buffer.append(o)\n",
        "        return np.concatenate(self.buffer), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        actions = [[0.0] * self.env.action_space[0].shape[0] for _ in range(self.n_buildings)]\n",
        "        actions[self.building_id] = [float(action[0])]\n",
        "        obs, reward, done, trunc, info = self.env.step(actions)\n",
        "        o = obs[self.building_id]\n",
        "        self.buffer.pop(0)\n",
        "        self.buffer.append(o)\n",
        "        return np.concatenate(self.buffer), reward[self.building_id], done, trunc, info\n",
        "\n",
        "# ========== Feature Extractor ==========\n",
        "class GNN_LSTM_FeatureExtractor(BaseFeaturesExtractor):\n",
        "    def __init__(self, observation_space, env, hidden_size=64, lstm_layers=1):\n",
        "        super().__init__(observation_space, features_dim=hidden_size)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.obs_dim = observation_space.shape[0] // 12\n",
        "        self.lstm = nn.LSTM(self.obs_dim, hidden_size, lstm_layers, batch_first=True)\n",
        "        self.hidden = None\n",
        "        self.env = env\n",
        "        self.building_id = env.building_id if hasattr(env, 'building_id') else 0\n",
        "        self.graph_x = torch.zeros((len(env.buildings), 3), dtype=torch.float32)\n",
        "        self.edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "        self.edge_attr = torch.empty((0, 1), dtype=torch.float32)\n",
        "        self.gnn1 = GATv2Conv(3, hidden_size, edge_dim=1)\n",
        "        self.gnn2 = GATv2Conv(hidden_size, hidden_size, edge_dim=1)\n",
        "\n",
        "    def update_graph(self):\n",
        "        graph_x, edge_index, edge_attr = build_dynamic_graph(self.env)\n",
        "        self.graph_x = graph_x\n",
        "        self.edge_index = edge_index\n",
        "        self.edge_attr = edge_attr\n",
        "\n",
        "    def forward(self, obs):\n",
        "        batch_size = obs.shape[0]\n",
        "        x = obs.view(batch_size, 12, self.obs_dim).float()\n",
        "        if self.hidden is None or self.hidden[0].shape[1] != batch_size:\n",
        "            h0 = torch.zeros(self.lstm.num_layers, batch_size, self.hidden_size).to(x.device)\n",
        "            c0 = torch.zeros(self.lstm.num_layers, batch_size, self.hidden_size).to(x.device)\n",
        "            self.hidden = (h0, c0)\n",
        "        lstm_out, self.hidden = self.lstm(x, self.hidden)\n",
        "        self.hidden = (self.hidden[0].detach(), self.hidden[1].detach())\n",
        "        lstm_feature = lstm_out[:, -1, :]\n",
        "\n",
        "        gx = self.graph_x.to(x.device)\n",
        "        ei = self.edge_index.to(x.device)\n",
        "        ea = self.edge_attr.to(x.device)\n",
        "        gx = torch.relu(self.gnn1(gx, ei, ea))\n",
        "        gx = torch.relu(self.gnn2(gx, ei, ea))\n",
        "\n",
        "\n",
        "        gnn_feature = gx[self.building_id].unsqueeze(0).expand(batch_size, -1)\n",
        "\n",
        "        return lstm_feature + gnn_feature\n",
        "\n",
        "# ========== Policy ==========\n",
        "class CustomGNNLSTMPolicy(ActorCriticPolicy):\n",
        "    def __init__(self, observation_space, action_space, lr_schedule, env, **kwargs):\n",
        "        super().__init__(\n",
        "            observation_space,\n",
        "            action_space,\n",
        "            lr_schedule,\n",
        "            features_extractor_class=GNN_LSTM_FeatureExtractor,\n",
        "            features_extractor_kwargs={\"env\": env},\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "# ========== Callback ==========\n",
        "class DynamicGraphCallback(BaseCallback):\n",
        "    def __init__(self, verbose=0):\n",
        "        super().__init__(verbose)\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        self.model.policy.features_extractor.update_graph()\n",
        "        return True\n",
        "\n",
        "# ========== Main ==========\n",
        "if __name__ == '__main__':\n",
        "    env = CityLearnEnv(\n",
        "        schema='citylearn_challenge_2022_phase_1',\n",
        "        reward_function=SimpleReward,\n",
        "        central_agent=False\n",
        "    )\n",
        "\n",
        "    single_building_env = CityLearnSingleBuildingWrapper(env, building_id=0, seq_len=12)\n",
        "    vec_env = DummyVecEnv([lambda: single_building_env])\n",
        "\n",
        "    model = PPO(\n",
        "        CustomGNNLSTMPolicy,\n",
        "        vec_env,\n",
        "        normalize_advantage=True,\n",
        "        verbose=1,\n",
        "        n_steps=1024,\n",
        "        batch_size=64,\n",
        "        learning_rate=3e-4,\n",
        "        gamma=0.99,\n",
        "        gae_lambda=0.95,\n",
        "        ent_coef=0.01,\n",
        "        vf_coef=0.4,\n",
        "        max_grad_norm=0.5,\n",
        "        policy_kwargs={\"env\": env}\n",
        "    )\n",
        "\n",
        "    model.policy.features_extractor.update_graph()\n",
        "\n",
        "    eval_env = DummyVecEnv([\n",
        "        lambda: Monitor(CityLearnSingleBuildingWrapper(env, building_id=0, seq_len=12))\n",
        "    ])\n",
        "    eval_callback = EvalCallback(\n",
        "        eval_env,\n",
        "        best_model_save_path=\"./logs/best_model\",\n",
        "        log_path=\"./logs/eval\",\n",
        "        eval_freq=1024,\n",
        "        deterministic=True,\n",
        "        render=False\n",
        "    )\n",
        "\n",
        "    model.learn(total_timesteps=500_000, callback=[DynamicGraphCallback(), eval_callback])\n",
        "    model.save(\"ppo_gnn_lstm_dynamic_graph\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XwoMlFgjObwY",
        "outputId": "c250b4b9-8b35-419a-9bcf-6eb7cc416e6e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n",
            "INFO:root:The dataset names DNE in cache. Will download from intelligent-environments-lab/CityLearn/tree/v2.3.0 GitHub repository and write to /root/.cache/citylearn/v2.3.0/dataset_names.json. Next time DataSet.get_dataset_names is called, it will read from cache unless DataSet.clear_cache is run first.\n",
            "INFO:root:The citylearn_challenge_2022_phase_1 dataset DNE in cache. Will download from intelligent-environments-lab/CityLearn/tree/v2.3.0 GitHub repository and write to /root/.cache/citylearn/v2.3.0/datasets. Next time DataSet.get_dataset('citylearn_challenge_2022_phase_1') is called, it will read from cache unless DataSet.clear_cache is run first.\n",
            "INFO:root:The PV sizing data DNE in cache. Will download from intelligent-environments-lab/CityLearn/tree/v2.3.0 GitHub repository and write to /root/.cache/citylearn/v2.3.0/misc. Next time DataSet.get_pv_sizing_data is called, it will read from cache unless DataSet.clear_cache is run first.\n",
            "INFO:root:The battery sizing data DNE in cache. Will download from intelligent-environments-lab/CityLearn/tree/v2.3.0 GitHub repository and write to /root/.cache/citylearn/v2.3.0/misc. Next time DataSet.get_battery_sizing_data is called, it will read from cache unless DataSet.clear_cache is run first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Eval num_timesteps=1024, episode_reward=-2451.72 +/- 0.11\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 8.76e+03  |\n",
            "|    mean_reward     | -2.45e+03 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1024      |\n",
            "----------------------------------\n",
            "New best mean reward!\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1    |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 612  |\n",
            "|    total_timesteps | 1024 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=2048, episode_reward=-2587.94 +/- 0.43\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -2.59e+03    |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 2048         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016967272 |\n",
            "|    clip_fraction        | 0.00488      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0.000977     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 22.4         |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00103     |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 94.5         |\n",
            "------------------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1    |\n",
            "|    iterations      | 2    |\n",
            "|    time_elapsed    | 1214 |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=3072, episode_reward=-2585.43 +/- 0.12\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 8.76e+03    |\n",
            "|    mean_reward          | -2.59e+03   |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 3072        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004287388 |\n",
            "|    clip_fraction        | 0.021       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.43       |\n",
            "|    explained_variance   | 0.0792      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 38.4        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.003      |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 109         |\n",
            "-----------------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1    |\n",
            "|    iterations      | 3    |\n",
            "|    time_elapsed    | 1814 |\n",
            "|    total_timesteps | 3072 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=4096, episode_reward=-2586.81 +/- 0.30\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -2.59e+03    |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026875078 |\n",
            "|    clip_fraction        | 0.024        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0.014        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 33.6         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00226     |\n",
            "|    std                  | 0.996        |\n",
            "|    value_loss           | 102          |\n",
            "------------------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1    |\n",
            "|    iterations      | 4    |\n",
            "|    time_elapsed    | 2406 |\n",
            "|    total_timesteps | 4096 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=5120, episode_reward=-2585.55 +/- 0.37\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 8.76e+03    |\n",
            "|    mean_reward          | -2.59e+03   |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 5120        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004406916 |\n",
            "|    clip_fraction        | 0.0129      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.42       |\n",
            "|    explained_variance   | 0.00881     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 33          |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00132    |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 98.3        |\n",
            "-----------------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1    |\n",
            "|    iterations      | 5    |\n",
            "|    time_elapsed    | 3008 |\n",
            "|    total_timesteps | 5120 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=6144, episode_reward=-2388.00 +/- 0.00\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -2.39e+03    |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041517434 |\n",
            "|    clip_fraction        | 0.0174       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0.0171       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 28.2         |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.00189     |\n",
            "|    std                  | 0.999        |\n",
            "|    value_loss           | 86.4         |\n",
            "------------------------------------------\n",
            "New best mean reward!\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1    |\n",
            "|    iterations      | 6    |\n",
            "|    time_elapsed    | 3610 |\n",
            "|    total_timesteps | 6144 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=7168, episode_reward=-2139.55 +/- 0.02\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 8.76e+03    |\n",
            "|    mean_reward          | -2.14e+03   |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 7168        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001606904 |\n",
            "|    clip_fraction        | 0.00693     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | 0.0556      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 25.4        |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.00325    |\n",
            "|    std                  | 0.989       |\n",
            "|    value_loss           | 82.5        |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1    |\n",
            "|    iterations      | 7    |\n",
            "|    time_elapsed    | 4206 |\n",
            "|    total_timesteps | 7168 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=8192, episode_reward=-2302.48 +/- 0.00\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -2.3e+03     |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039281626 |\n",
            "|    clip_fraction        | 0.0418       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.4         |\n",
            "|    explained_variance   | 0.0724       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 20.2         |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.00528     |\n",
            "|    std                  | 0.971        |\n",
            "|    value_loss           | 74.1         |\n",
            "------------------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1    |\n",
            "|    iterations      | 8    |\n",
            "|    time_elapsed    | 4798 |\n",
            "|    total_timesteps | 8192 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=9216, episode_reward=-2664.54 +/- 0.01\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 8.76e+03    |\n",
            "|    mean_reward          | -2.66e+03   |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 9216        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003662945 |\n",
            "|    clip_fraction        | 0.0243      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.38       |\n",
            "|    explained_variance   | 0.109       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 23.6        |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.00468    |\n",
            "|    std                  | 0.958       |\n",
            "|    value_loss           | 74.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1    |\n",
            "|    iterations      | 9    |\n",
            "|    time_elapsed    | 5393 |\n",
            "|    total_timesteps | 9216 |\n",
            "-----------------------------\n",
            "Eval num_timesteps=10240, episode_reward=-3791.63 +/- 0.00\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -3.79e+03    |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042109597 |\n",
            "|    clip_fraction        | 0.0442       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | 0.114        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 21.4         |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.00459     |\n",
            "|    std                  | 0.958        |\n",
            "|    value_loss           | 66.9         |\n",
            "------------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 1     |\n",
            "|    iterations      | 10    |\n",
            "|    time_elapsed    | 5982  |\n",
            "|    total_timesteps | 10240 |\n",
            "------------------------------\n",
            "Eval num_timesteps=11264, episode_reward=-3056.15 +/- 0.00\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -3.06e+03    |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 11264        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034210288 |\n",
            "|    clip_fraction        | 0.0201       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | 0.145        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 24.6         |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -0.00294     |\n",
            "|    std                  | 0.961        |\n",
            "|    value_loss           | 70.7         |\n",
            "------------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 1     |\n",
            "|    iterations      | 11    |\n",
            "|    time_elapsed    | 6572  |\n",
            "|    total_timesteps | 11264 |\n",
            "------------------------------\n",
            "Eval num_timesteps=12288, episode_reward=-2737.80 +/- 0.35\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -2.74e+03    |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 12288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047223717 |\n",
            "|    clip_fraction        | 0.0216       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | 0.162        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 25.7         |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.00323     |\n",
            "|    std                  | 0.957        |\n",
            "|    value_loss           | 66.6         |\n",
            "------------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 1     |\n",
            "|    iterations      | 12    |\n",
            "|    time_elapsed    | 7187  |\n",
            "|    total_timesteps | 12288 |\n",
            "------------------------------\n",
            "Eval num_timesteps=13312, episode_reward=-2691.04 +/- 0.02\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -2.69e+03    |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 13312        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017612994 |\n",
            "|    clip_fraction        | 0.0177       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | 0.178        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 20.7         |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -0.00254     |\n",
            "|    std                  | 0.965        |\n",
            "|    value_loss           | 65.6         |\n",
            "------------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 1     |\n",
            "|    iterations      | 13    |\n",
            "|    time_elapsed    | 7812  |\n",
            "|    total_timesteps | 13312 |\n",
            "------------------------------\n",
            "Eval num_timesteps=14336, episode_reward=-2803.91 +/- 0.36\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -2.8e+03     |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018143656 |\n",
            "|    clip_fraction        | 0.00801      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 0.222        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 29.3         |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | -0.00289     |\n",
            "|    std                  | 0.973        |\n",
            "|    value_loss           | 63.1         |\n",
            "------------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 1     |\n",
            "|    iterations      | 14    |\n",
            "|    time_elapsed    | 8399  |\n",
            "|    total_timesteps | 14336 |\n",
            "------------------------------\n",
            "Eval num_timesteps=15360, episode_reward=-2540.67 +/- 0.02\n",
            "Episode length: 8759.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 8.76e+03     |\n",
            "|    mean_reward          | -2.54e+03    |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 15360        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034595225 |\n",
            "|    clip_fraction        | 0.0165       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 0.233        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 27.7         |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -0.000878    |\n",
            "|    std                  | 0.971        |\n",
            "|    value_loss           | 62.1         |\n",
            "------------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 1     |\n",
            "|    iterations      | 15    |\n",
            "|    time_elapsed    | 8988  |\n",
            "|    total_timesteps | 15360 |\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1170134793.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    210\u001b[0m     )\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500_000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDynamicGraphCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ppo_gnn_lstm_dynamic_graph\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     ) -> SelfPPO:\n\u001b[0;32m--> 315\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    316\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# Give access to local variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_locals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/callbacks.py\u001b[0m in \u001b[0;36mon_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/callbacks.py\u001b[0m in \u001b[0;36m_on_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;31m# Return False (stop training) if at least one callback returns False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/callbacks.py\u001b[0m in \u001b[0;36mon_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/callbacks.py\u001b[0m in \u001b[0;36m_on_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_success_buffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m             episode_rewards, episode_lengths = evaluate_policy(\n\u001b[0m\u001b[1;32m    461\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_env\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py\u001b[0m in \u001b[0;36mevaluate_policy\u001b[0;34m(model, env, n_eval_episodes, deterministic, render, callback, reward_threshold, return_episode_rewards, warn)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         )\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mnew_observations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mcurrent_rewards\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mcurrent_lengths\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \"\"\"\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Avoid circular imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/monitor.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tried to step environment that needs reset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mterminated\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1170134793.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_buildings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilding_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilding_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/citylearn/citylearn.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;31m# env, which is not the best design for competition integrity sake. Will revisit the building.observations() function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0;31m# to see how it can be optimized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m         \u001b[0mreward_observations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiodic_normalization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuildings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreward_observations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__rewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/citylearn/citylearn.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;31m# env, which is not the best design for competition integrity sake. Will revisit the building.observations() function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0;31m# to see how it can be optimized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m         \u001b[0mreward_observations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiodic_normalization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuildings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreward_observations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__rewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/citylearn/building.py\u001b[0m in \u001b[0;36mobservations\u001b[0;34m(self, include_all, normalize, periodic_normalization, check_limits)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mobservations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_observations_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minclude_all\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/citylearn/building.py\u001b[0m in \u001b[0;36m_get_observations_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_observations_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         return {\n\u001b[0;32m--> 961\u001b[0;31m             **{\n\u001b[0m\u001b[1;32m    962\u001b[0m                 \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menergy_simulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menergy_simulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/citylearn/building.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_observations_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         return {\n\u001b[0;32m--> 961\u001b[0;31m             **{\n\u001b[0m\u001b[1;32m    962\u001b[0m                 \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menergy_simulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menergy_simulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🧪 Анализа на тренинг логовите (SimpleReward агент)\n",
        "\n",
        "Следи табела со селектирани метрики од логовите:\n",
        "\n",
        "| Timesteps | Mean Reward | Entropy Loss | Value Loss | Policy Grad Loss | Explained Variance |\n",
        "|-----------|-------------|---------------|-------------|------------------|---------------------|\n",
        "| 1024      | -2451.72    | -1.42         | 94.5        | -0.0010          | 0.0009              |\n",
        "| 3072      | -2585.43    | -1.43         | 109         | -0.0030          | 0.0792              |\n",
        "| 5120      | -2585.55    | -1.42         | 98.3        | -0.0013          | 0.0088              |\n",
        "| 7168      | -2139.55 ✅ | -1.41         | 82.5        | -0.0033          | 0.0556              |\n",
        "| 9216      | -2664.54 🔻 | -1.38         | 74.7        | -0.0047          | 0.109               |\n",
        "| 10240     | -3791.63 ❌ | -1.38         | 66.9        | -0.0046          | 0.114               |\n",
        "| 12288     | -2737.80    | -1.38         | 66.6        | -0.0032          | 0.162               |\n",
        "| 14336     | -2803.91    | -1.39         | 63.1        | -0.0029          | 0.222               |\n",
        "| 15360     | -2540.67    | -1.39         | 62.1        | -0.0009          | 0.233               |\n",
        "\n",
        "### ✅ Заклучоци:\n",
        "- **Entropy Loss** опаѓа: агентот станува посигурен во изборите.\n",
        "- **Mean Reward** прво се подобрува, потоа има пад околу 10240 чекори, но на крај повторно расте.\n",
        "- **Explained Variance** расте: value мрежата станува попрецизна.\n",
        "- **Policy Gradient Loss** е најголем во средина на тренингот, што укажува на најголеми промени во политика.\n",
        "\n",
        "Тренингот има нестабилен reward тренд, но стабилни подобрувања во мрежите. Агентот покажува способност да се опорави по лош reward.\n"
      ],
      "metadata": {
        "id": "g7qb6Ya0kBSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "\n",
        "eval_data_path = '/content/logs/eval/evaluations_SimpleReward.npz'\n",
        "\n",
        "try:\n",
        "\n",
        "    data = np.load(eval_data_path)\n",
        "\n",
        "\n",
        "    timesteps = data['timesteps']\n",
        "    results = data['results']\n",
        "\n",
        "\n",
        "    mean_rewards = np.mean(results, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(timesteps, mean_rewards, label='Mean Evaluation Reward')\n",
        "    plt.title('Agent Performance During Training (Evaluation Callback)')\n",
        "    plt.xlabel('Timesteps')\n",
        "    plt.ylabel('Mean Reward')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"✅ Loaded {len(timesteps)} evaluation points.\")\n",
        "    print(f\"First 5 timesteps: {timesteps[:5]}\")\n",
        "    print(f\"First 5 mean rewards: {mean_rewards[:5]}\")\n",
        "    print(f\"Shape of 'results' array: {results.shape}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"❌ Error: evaluations.npz not found at {eval_data_path}\")\n",
        "    print(\"Please ensure the path is correct and the EvalCallback was configured to save this file.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ An unexpected error occurred: {e}\")\n",
        "    print(f\"Keys available in npz: {list(data.keys())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "W4C_hKSRrkpo",
        "outputId": "99c42e0f-f7c0-4ecf-e585-1a8097ffe491"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded 15 evaluation points.\n",
            "First 5 timesteps: [1024 2048 3072 4096 5120]\n",
            "First 5 mean rewards: [-2451.7235226 -2587.9446404 -2585.4262848 -2586.8060212 -2585.5498926]\n",
            "Shape of 'results' array: (15, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📉 Графикон: Просечна награда за време на тренирање (SimpleReward)\n",
        "\n",
        "Овој графикон ја прикажува евалуациската награда за време на тренирањето на агентот кој користи поедноставена наградна функција. Забележливо е:\n",
        "\n",
        "- ✅ Почетна **стабилност**, со релативно мали осцилации до околу 7000 чекори.\n",
        "- 📈 Постепено подобрување со пик околу 7500 чекори (најдобра награда во тој период).\n",
        "- ⚠️ Потоа следи **нагло влошување** помеѓу 8500 и 10500 чекори, каде што наградата паѓа до најниската вредност.\n",
        "- 🔁 Во втората половина од тренирањето, агентот успева да се **опорави**, но не го достигнува претходниот максимум.\n",
        "\n",
        "🔍 Оваа динамика укажува дека **агентот е нестабилен при учење**, можеби поради:\n",
        "- Недоволен баланс на компонентите во наградната функција.\n",
        "- Непредвидливи однесувања кои не се санкционираат доволно.\n",
        "- Премногу „прости“ насоки за учење, што води до нагли осцилации.\n",
        "\n",
        "➡️ Во споредба со првиот reward, **овој пристап изгледа помалку стабилен и помалку ефикасен во преносливото учење**. Можеби ќе биде потребно дополнително фино подесување или комбинирање на оваа функција со други компоненти (цена, стабилност, удобност).\n"
      ],
      "metadata": {
        "id": "i9eVN6aCjW9r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Тестирање на преносливост на агентот на нови згради\n",
        "\n",
        "Во следните неколку чекори се извршува евалуација на PPO агентот, трениран без GNN, на згради кои не биле дел од процесот на тренинг.\n",
        "\n",
        "За секоја зграда:\n",
        "- Се иницијализира нова средина со **CityLearnSingleBuildingWrapper**, која го изолира однесувањето само за избраната зграда.\n",
        "- Агентот е вчитан од `best_model_without_GNN_400.zip`.\n",
        "- Се извршува една епизода на симулација во која агентот носи детерминирани одлуки (`deterministic=True`).\n",
        "- Вкупната награда добиена од епизодата се собира во `total_reward` и се прикажува.\n",
        "\n",
        "### 🎯 Цел:\n",
        "Да се процени **генерализацијата** и **преносливоста** на агентот кој бил трениран на една зграда, кон **други згради со различна потрошувачка, капацитет на батерии и соларна продукција**.\n",
        "\n",
        "Оваа анализа е клучна за да се утврди:\n",
        "- дали агентот научил општа стратегија, или\n",
        "- дали е приспособен исклучиво на карактеристиките на зградата на која бил трениран.\n",
        "\n",
        "Овој дел е особено важен за **споредба со GNN агентот**, кај кого информацијата од мрежата на згради (граф) би требало да го подобри преносот кон други згради."
      ],
      "metadata": {
        "id": "9on0hCgjkQu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "env = CityLearnEnv(\n",
        "    schema='citylearn_challenge_2022_phase_1',\n",
        "    reward_function=SimpleReward,\n",
        "    central_agent=False\n",
        ")\n",
        "\n",
        "test_building_id = 2  # пробај со друга зграда\n",
        "eval_env = CityLearnSingleBuildingWrapper(env, building_id=test_building_id, seq_len=12)\n",
        "\n",
        "model = PPO.load(\"best_model_SimpleReward.zip\")\n",
        "\n",
        "obs, _ = eval_env.reset()\n",
        "done = False\n",
        "total_reward = 0\n",
        "\n",
        "while not done:\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, _, _ = eval_env.step(action)\n",
        "    total_reward += reward\n",
        "\n",
        "print(f\"📊 Total reward on unseen building {test_building_id}: {total_reward:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfrA8dJyryHb",
        "outputId": "c28988a2-1094-4807-e3b3-ed21731a952e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Total reward on unseen building 2: -510.71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "env = CityLearnEnv(\n",
        "    schema='citylearn_challenge_2022_phase_1',\n",
        "    reward_function=SimpleReward,\n",
        "    central_agent=False\n",
        ")\n",
        "\n",
        "test_building_id = 4  # пробај со друга зграда\n",
        "eval_env = CityLearnSingleBuildingWrapper(env, building_id=test_building_id, seq_len=12)\n",
        "\n",
        "model = PPO.load(\"best_model_SimpleReward.zip\")\n",
        "\n",
        "obs, _ = eval_env.reset()\n",
        "done = False\n",
        "total_reward = 0\n",
        "\n",
        "while not done:\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, _, _ = eval_env.step(action)\n",
        "    total_reward += reward\n",
        "\n",
        "print(f\"📊 Total reward on unseen building {test_building_id}: {total_reward:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4ux5RnpsZdh",
        "outputId": "c845d59c-debd-4110-ebd2-93597cffc52e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Total reward on unseen building 4: -1775.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "env = CityLearnEnv(\n",
        "    schema='citylearn_challenge_2022_phase_1',\n",
        "    reward_function=SimpleReward,\n",
        "    central_agent=False\n",
        ")\n",
        "\n",
        "test_building_id = 1  # пробај со друга зграда\n",
        "eval_env = CityLearnSingleBuildingWrapper(env, building_id=test_building_id, seq_len=12)\n",
        "\n",
        "model = PPO.load(\"best_model_SimpleReward.zip\")\n",
        "\n",
        "obs, _ = eval_env.reset()\n",
        "done = False\n",
        "total_reward = 0\n",
        "\n",
        "while not done:\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, _, _ = eval_env.step(action)\n",
        "    total_reward += reward\n",
        "\n",
        "print(f\"📊 Total reward on unseen building {test_building_id}: {total_reward:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sweyzA-1u60P",
        "outputId": "b0e7ef5f-2e52-4b75-e5eb-6813e47ca934"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Total reward on unseen building 1: -3076.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "env = CityLearnEnv(\n",
        "    schema='citylearn_challenge_2022_phase_1',\n",
        "    reward_function=SimpleReward,\n",
        "    central_agent=False\n",
        ")\n",
        "\n",
        "test_building_id = 3  # пробај со друга зграда\n",
        "eval_env = CityLearnSingleBuildingWrapper(env, building_id=test_building_id, seq_len=12)\n",
        "\n",
        "model = PPO.load(\"best_model_SimpleReward.zip\")\n",
        "\n",
        "obs, _ = eval_env.reset()\n",
        "done = False\n",
        "total_reward = 0\n",
        "\n",
        "while not done:\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, _, _ = eval_env.step(action)\n",
        "    total_reward += reward\n",
        "\n",
        "print(f\"📊 Total reward on unseen building {test_building_id}: {total_reward:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZiXDdE9vAh9",
        "outputId": "6bb65147-c1ba-4305-b09d-7b6e534e27b9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Total reward on unseen building 3: -3660.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📊 Споредба на агенти со различни Reward Functions\n",
        "\n",
        "Откако беа тренирани два PPO агенти со иста архитектура (вклучувајќи GNN и LSTM), но со различни функции за награда (`CustomReward` и `SimpleReward`), направена е евалуација на нивната способност да се пренесат на други згради.\n",
        "\n",
        "### ✅ Резултати од евалуација по зграда\n",
        "\n",
        "| Зграда | Агент со `CustomReward` | Агент со `SimpleReward` |\n",
        "|--------|--------------------------|---------------------------|\n",
        "| 2      | -138.24                  | -510.71                   |\n",
        "| 3      | -625.10                  | -3660.65                  |\n",
        "| 4      | -579.69                  | -1775.88                  |\n",
        "| 1      | -903.35                  | -3076.81                  |\n",
        "\n",
        "---\n",
        "\n",
        "###  Анализа:\n",
        "\n",
        "- Агентот со `CustomReward` значително подобро се пренесува на сите тест-згради.\n",
        "- Посебно се истакнува разликата кај:\n",
        "  - Зграда **2**, каде перформансот е подобар за **372 поени**.\n",
        "  - Зграда **3**, каде `SimpleReward` има многу послаби резултати (-3660).\n",
        "- `SimpleReward` се покажува како премногу едноставна и не ги зема предвид цените на електрична енергија и флексибилното управување со батеријата во сложени сценарија.\n",
        "- `CustomReward`, иако посложена, води до подобро однесување благодарение на повеќеслојната логика што ги наградува енергетски ефективните акции и управувањето со батеријата според цена.\n",
        "\n",
        "---\n",
        "\n",
        "###  Заклучок:\n",
        "\n",
        "➡️ Агентот со **CustomReward** демонстрира подобра генерализација и интелигентно однесување на нови згради, додека едноставниот reward води до слаби резултати.  \n",
        "➡️ Дизајнот на наградната функција е клучен фактор за успешноста на RL агентите во CityLearn.\n"
      ],
      "metadata": {
        "id": "wyL2cAUPo3Ia"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}